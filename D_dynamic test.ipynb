{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T13:25:37.760301Z",
     "start_time": "2018-10-19T13:25:37.707508Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T13:25:39.216923Z",
     "start_time": "2018-10-19T13:25:37.770286Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "Software versions": [
        {
         "module": "Python",
         "version": "3.6.5 64bit [GCC 4.2.1 Compatible Apple LLVM 9.1.0 (clang-902.0.39.2)]"
        },
        {
         "module": "IPython",
         "version": "7.0.1"
        },
        {
         "module": "OS",
         "version": "Darwin 18.0.0 x86_64 i386 64bit"
        },
        {
         "module": "numpy",
         "version": "1.15.2"
        },
        {
         "module": "dlib",
         "version": "19.16.0"
        },
        {
         "module": "matplotlib",
         "version": "3.0.0"
        },
        {
         "module": "imageio",
         "version": "2.4.1"
        },
        {
         "module": "gaze",
         "version": "The 'gaze' distribution was not found and is required by the application"
        },
        {
         "module": "torch",
         "version": "0.4.1"
        },
        {
         "module": "torchvision",
         "version": "0.2.1"
        }
       ]
      },
      "text/html": [
       "<table><tr><th>Software</th><th>Version</th></tr><tr><td>Python</td><td>3.6.5 64bit [GCC 4.2.1 Compatible Apple LLVM 9.1.0 (clang-902.0.39.2)]</td></tr><tr><td>IPython</td><td>7.0.1</td></tr><tr><td>OS</td><td>Darwin 18.0.0 x86_64 i386 64bit</td></tr><tr><td>numpy</td><td>1.15.2</td></tr><tr><td>dlib</td><td>19.16.0</td></tr><tr><td>matplotlib</td><td>3.0.0</td></tr><tr><td>imageio</td><td>2.4.1</td></tr><tr><td>gaze</td><td>The 'gaze' distribution was not found and is required by the application</td></tr><tr><td>torch</td><td>0.4.1</td></tr><tr><td>torchvision</td><td>0.2.1</td></tr><tr><td colspan='2'>Fri Oct 19 15:25:39 2018 CEST</td></tr></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{|l|l|}\\hline\n",
       "{\\bf Software} & {\\bf Version} \\\\ \\hline\\hline\n",
       "Python & 3.6.5 64bit [GCC 4.2.1 Compatible Apple LLVM 9.1.0 (clang-902.0.39.2)] \\\\ \\hline\n",
       "IPython & 7.0.1 \\\\ \\hline\n",
       "OS & Darwin 18.0.0 x86\\_64 i386 64bit \\\\ \\hline\n",
       "numpy & 1.15.2 \\\\ \\hline\n",
       "dlib & 19.16.0 \\\\ \\hline\n",
       "matplotlib & 3.0.0 \\\\ \\hline\n",
       "imageio & 2.4.1 \\\\ \\hline\n",
       "gaze & The 'gaze' distribution was not found and is required by the application \\\\ \\hline\n",
       "torch & 0.4.1 \\\\ \\hline\n",
       "torchvision & 0.2.1 \\\\ \\hline\n",
       "\\hline \\multicolumn{2}{|l|}{Fri Oct 19 15:25:39 2018 CEST} \\\\ \\hline\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "Software versions\n",
       "Python 3.6.5 64bit [GCC 4.2.1 Compatible Apple LLVM 9.1.0 (clang-902.0.39.2)]\n",
       "IPython 7.0.1\n",
       "OS Darwin 18.0.0 x86_64 i386 64bit\n",
       "numpy 1.15.2\n",
       "dlib 19.16.0\n",
       "matplotlib 3.0.0\n",
       "imageio 2.4.1\n",
       "gaze The 'gaze' distribution was not found and is required by the application\n",
       "torch 0.4.1\n",
       "torchvision 0.2.1\n",
       "Fri Oct 19 15:25:39 2018 CEST"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext version_information\n",
    "%version_information numpy, dlib, matplotlib, imageio, gaze, torch, torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T13:25:39.719305Z",
     "start_time": "2018-10-19T13:25:39.230160Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T13:25:39.762205Z",
     "start_time": "2018-10-19T13:25:39.724422Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters= {'dataset_folder': 'dataset', 'dataset_faces_folder': 'dataset_faces', 'batch_size': 8, 'test_batch_size': 1, 'size_test_set': 0.2, 'epochs': 40, 'do_adam': False, 'lr': 0.01, 'momentum': 0.05, 'no_cuda': True, 'num_processes': 1, 'seed': 42, 'log_interval': 0, 'fullsize': 75, 'crop': 64, 'size': 90, 'mean': 0.4, 'std': 0.3, 'conv1_dim': 9, 'conv1_kernel_size': 18, 'conv2_dim': 36, 'conv2_kernel_size': 14, 'conv1_bn_momentum': 0.5, 'conv2_bn_momentum': 0.5, 'dense_bn_momentum': 0.9, 'stride1': 2, 'stride2': 4, 'N_cv': 20, 'dimension': 30, 'verbose': 1}\n"
     ]
    }
   ],
   "source": [
    "from gaze import init\n",
    "args = init(no_cuda=True, verbose=1)\n",
    "print('Parameters=', args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T13:25:39.927091Z",
     "start_time": "2018-10-19T13:25:39.765414Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2221 sample images;  1777  to train 444 to test\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['blink', 'center', 'left', 'right']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gaze import Data\n",
    "d = Data(args)\n",
    "d.dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T13:25:40.015778Z",
     "start_time": "2018-10-19T13:25:39.930290Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty line\n",
      "🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫\n",
      "Fixation dot\n",
      "🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🔵🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫\n",
      "label= left\n",
      "🌫🌫🔴🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫\n",
      "label= blink\n",
      "🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫☠️🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫\n",
      "label= center\n",
      "🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🔴🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫\n",
      "label= right\n",
      "🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🌫🔴🌫🌫\n"
     ]
    }
   ],
   "source": [
    "targets = {}\n",
    "s_target = '🔴'\n",
    "s_fixat = '🔵'\n",
    "s_distra = '🌫'\n",
    "s_blink = '☠️'\n",
    "\n",
    "N_dis = 30 # <<<<<<<<<<<< change to adapt to your notebook's width\n",
    "N_margin = 2\n",
    "\n",
    "targets['left'] = N_margin * s_distra + s_target + 2 * N_dis * s_distra + N_margin * s_distra\n",
    "\n",
    "targets['blink'] = N_margin * s_distra + N_dis * s_distra + s_blink + N_dis * s_distra + N_margin * s_distra\n",
    "\n",
    "targets['center'] = N_margin * s_distra + N_dis * s_distra + s_target + N_dis * s_distra + N_margin * s_distra\n",
    "\n",
    "targets['right'] = N_margin * s_distra + 2 * N_dis * s_distra + s_target + N_margin * s_distra\n",
    "\n",
    "print ('Empty line')\n",
    "null = N_margin * s_distra +  (2 * N_dis + 1) * s_distra + N_margin * s_distra\n",
    "print (null)\n",
    "print ('Fixation dot')\n",
    "center = N_margin * s_distra + N_dis * s_distra + s_fixat + N_dis * s_distra + N_margin * s_distra\n",
    "print (center)\n",
    "\n",
    "for label in targets.keys():\n",
    "    print('label=', label)\n",
    "    print (targets[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "source": [
    "# dynamical test : offline detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T13:25:42.588887Z",
     "start_time": "2018-10-19T13:25:40.018914Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/laurentperrinet/research/LeCheapEyeTracker/src/LeCheapEyeTracker/haarcascade_frontalface_default.xml\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from LeCheapEyeTracker.EyeTrackerServer import Server\n",
    "#from LeCheapEyeTracker.EyeTrackerClient import Client\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T13:25:42.658797Z",
     "start_time": "2018-10-19T13:25:42.591870Z"
    }
   },
   "outputs": [],
   "source": [
    "def grab(classes, N_frame=32, startup_time=1., interframe_time=0.3, random=False, display=False):\n",
    "    try:\n",
    "        import time\n",
    "        time.sleep(startup_time)\n",
    "        et = Server()\n",
    "        frame = et.cam.grab()[:, :, ::-1]\n",
    "        N_X, N_Y, three = frame.shape\n",
    "\n",
    "        frames = []\n",
    "        labels = []\n",
    "        timings_frame = []\n",
    "        \n",
    "        N_classes = len(classes)\n",
    "        timings_cv = []\n",
    "        i_choice_old = 42\n",
    "        \n",
    "        T0 = time.time()\n",
    "        for i in range(N_frame):\n",
    "            try:\n",
    "                t0 = time.time()\n",
    "                frames.append(et.cam.grab()[:, :, ::-1])\n",
    "                timings_frame.append(time.time()-T0)\n",
    "                t1 = time.time()\n",
    "                timings_cv.append(t1-t0)\n",
    "                \n",
    "                if display:\n",
    "                    plt.imshow(frames[i, ...])\n",
    "                    plt.show() \n",
    "                else:\n",
    "                    # presentation of stimulus\n",
    "                    if random:\n",
    "                        i_choice = np.random.randint(N_classes)\n",
    "                    else:\n",
    "                        i_choice = (i // int(N_frame/N_classes) + 1) % N_classes\n",
    "                    #label = list(targets.keys())[i_choice]\n",
    "                    label = classes[i_choice]\n",
    "                    labels.append(label)\n",
    "                    if not i_choice == i_choice_old:\n",
    "                        clear_output()\n",
    "                        print(null)\n",
    "                        print(null)\n",
    "                        print(targets[label])\n",
    "                        print(null)\n",
    "                        print(null)                    \n",
    "                        i_choice_old = i_choice\n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "            time.sleep(interframe_time)            \n",
    "    finally:\n",
    "        et.close()\n",
    "        \n",
    "    for timings, label in [(timings_cv, 'openCV')] :\n",
    "        timings = np.array(timings)*1000\n",
    "        print('For', label, ', timings in ms = %.3f' % timings.mean(), '+/- %.3f' % timings.std()) \n",
    "\n",
    "    return frames, labels, timings_frame\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T13:25:42.698811Z",
     "start_time": "2018-10-19T13:25:42.663091Z"
    }
   },
   "outputs": [],
   "source": [
    "filename = '/tmp/dump_frames.pkl'\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T13:25:43.162943Z",
     "start_time": "2018-10-19T13:25:42.703019Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(frames)= 200\n",
      "frames[0].shape= (480, 640, 3)\n",
      "timings_frame[:10]= [0.06694626808166504, 0.15369915962219238, 0.24228525161743164, 0.33193230628967285, 0.4058973789215088, 0.4933462142944336, 0.5717661380767822, 0.6604912281036377, 0.7374284267425537, 0.8259913921356201]\n",
      "timings_frame[-10:]= [15.899439334869385, 15.98871922492981, 16.065667152404785, 16.155076265335083, 16.23355722427368, 16.323066234588623, 16.39961814880371, 16.48927116394043, 16.56708312034607, 16.65637230873108]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open(filename, \"rb\") as f:\n",
    "        dic = pickle.load(f)\n",
    "        frames = dic['frames']\n",
    "        labels = dic['labels']\n",
    "        timings_frame = dic['timings_frame']\n",
    "except:\n",
    "    frames, labels, timings_frame = grab(d.dataset.classes, \n",
    "                                         N_frame=200, startup_time=1., interframe_time=0., display=False)        \n",
    "    with open(filename, \"wb\") as f:\n",
    "        pickle.dump({'frames':frames, 'labels':labels, 'timings_frame':timings_frame}, f)\n",
    "    \n",
    "print('len(frames)=', len(frames))\n",
    "print('frames[0].shape=', frames[0].shape)\n",
    "print('timings_frame[:10]=', timings_frame[:10])\n",
    "print('timings_frame[-10:]=', timings_frame[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T13:25:43.208682Z",
     "start_time": "2018-10-19T13:25:43.169137Z"
    }
   },
   "outputs": [],
   "source": [
    "#!rm {filename}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T13:26:26.527939Z",
     "start_time": "2018-10-19T13:25:43.215997Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Dlib , timings in ms = 210.5155611038208 +/- 51.5454902322891\n"
     ]
    }
   ],
   "source": [
    "def extract_faces(frames, do_bbox_once=False, display=False):\n",
    "    from gaze import FaceExtractor\n",
    "    F = FaceExtractor()\n",
    "    import time\n",
    "    timings_dlib = []\n",
    "\n",
    "    N_frame  = len(frames)\n",
    "    N_X, N_Y, three = frames[0].shape\n",
    "    from PIL import Image\n",
    "\n",
    "    img_faces = []\n",
    "    bbox = F.get_bbox(frames[0]) if do_bbox_once else None\n",
    "    \n",
    "    for i in range(N_frame):\n",
    "        if display:\n",
    "            plt.imshow(frames[i]/255)\n",
    "            plt.show() \n",
    "        t0 = time.time()\n",
    "        try:\n",
    "            img_face = F.face_extractor(frames[i], bbox=bbox)\n",
    "        except:\n",
    "            print('No face in frame#', i)\n",
    "        img_faces.append(img_face)\n",
    "        t1 = time.time()\n",
    "        timings_dlib.append(t1-t0)\n",
    "        if display:\n",
    "            plt.imshow(img_face)\n",
    "            plt.show() \n",
    "        \n",
    "    for timings, label in [(timings_dlib, 'Dlib')] :\n",
    "        timings = np.array(timings)*1000\n",
    "        print('For', label, ', timings in ms =', timings.mean(), '+/-', timings.std()) \n",
    "\n",
    "    return img_faces\n",
    "\n",
    "img_faces = extract_faces(frames)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "def classify(image, t):\n",
    "    from PIL import Image\n",
    "    image = Image.fromarray(image)#.astype('uint8'), 'RGB')\n",
    "    data = t(image)\n",
    "    data.unsqueeze_(0)\n",
    "    output = ml.model(data)    \n",
    "    return np.exp(output.data.numpy()[0, :].astype(np.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T13:26:26.586242Z",
     "start_time": "2018-10-19T13:26:26.531057Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2221 sample images;  1777  to train 444 to test\n"
     ]
    }
   ],
   "source": [
    "from gaze import ML\n",
    "ml = ML(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T13:26:26.650198Z",
     "start_time": "2018-10-19T13:26:26.590621Z"
    }
   },
   "outputs": [],
   "source": [
    "path = '_Regard_400.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T13:26:26.689370Z",
     "start_time": "2018-10-19T13:26:26.656017Z"
    }
   },
   "outputs": [],
   "source": [
    "path = '_Regard.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T13:27:31.019837Z",
     "start_time": "2018-10-19T13:26:26.710018Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Train Epoch:   0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected more than 1 value per channel when training, got input size [1, 30]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-73e072f15695>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/research/CatchTheEye/gaze.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, path, seed)\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training model...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#save the neural network state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model saved at'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/research/CatchTheEye/gaze.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, path, seed)\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Train Epoch'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0;31m# report classification results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_interval\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/research/CatchTheEye/gaze.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self, epoch, seed, rank)\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0;31m# Predict classes using images from the train set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m             \u001b[0;31m# Compute the loss based on the predictions and actual labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/research/CatchTheEye/gaze.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense_input_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense_bn_momentum\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense_bn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mACTIVATION\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             exponential_average_factor, self.eps)\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   1249\u001b[0m         \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Expected more than 1 value per channel when training, got input size {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m     return torch.batch_norm(\n\u001b[1;32m   1253\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected more than 1 value per channel when training, got input size [1, 30]"
     ]
    }
   ],
   "source": [
    "ml.train(path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T13:27:31.027952Z",
     "start_time": "2018-10-19T13:25:37.753Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def dyn_test(img_faces, labels, display=False, verbose=False):\n",
    "    import time\n",
    "    from PIL import Image\n",
    "    timings_torch = []\n",
    "    preds = []\n",
    "    for img_face, label in zip(img_faces, labels) :\n",
    "        t0 = time.time()\n",
    "        pred = ml.classify(img_face, ml.dataset.test_transform)\n",
    "        t1 = time.time()\n",
    "        timings_torch.append(t1-t0)\n",
    "        preds.append(pred)    \n",
    "        pred_label = ml.dataset.dataset.classes[pred.argmax()]\n",
    "        if verbose: print('Prediction =', pred_label, 'Shown label =', label)\n",
    "        if display:\n",
    "            plt.imshow(img_face)\n",
    "            plt.show() \n",
    "\n",
    "    for timings, label in [(timings_torch, 'torch')] :\n",
    "        timings = np.array(timings)*1000\n",
    "        print('For', label, ', timings in ms =', timings.mean(), '+/-', timings.std()) \n",
    "    return np.array(preds)\n",
    "        \n",
    "preds = dyn_test(img_faces, labels, display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T13:27:31.030625Z",
     "start_time": "2018-10-19T13:25:37.761Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=((16, 5)))\n",
    "ax = axs[0]\n",
    "x_label = np.array([-(l == 'left')  + (l == 'right') for l in labels])\n",
    "ax.plot(np.array(timings_frame)*1000, x_label, '--', lw=1, alpha=.5)\n",
    "p_b, p_c, p_l, p_r = preds[:, 0], preds[:, 1], preds[:, 2], preds[:, 3]\n",
    "ax.pcolor(np.array(timings_frame)*1000, np.array([-1, 1]), p_b[None,:], cmap=plt.get_cmap('binary'), alpha=.5)\n",
    "x_pred = 2 / np.pi * np.arctan2(p_r-p_l, p_c)\n",
    "#h_pred = (preds * np.log(preds)).sum(axis=1) / np.log(4)\n",
    "ax.plot(np.array(timings_frame)*1000, x_pred, lw=.5, alpha=.5)\n",
    "ax.scatter(np.array(timings_frame)*1000, x_pred, 14*(1-p_b), color='k')\n",
    "ax.set_xticklabels([])\n",
    "ax.set_ylabel('estimated position')\n",
    "ax.set_xlim(0, np.array(timings_frame).max()*1000 )\n",
    "ax.set_ylim(-1.05, 1.05)\n",
    "ax = axs[1]\n",
    "ax.pcolor(preds.T, cmap=plt.hot())\n",
    "label_num = [1*(l == 'center') + 2*(l == 'left')  + 3*(l == 'right') for l in labels]\n",
    "ax.plot(np.array(label_num)+.5, 'wo', ms=8)\n",
    "ax.plot(np.array(label_num)+.5, 'bo', ms=4)\n",
    "ax.set_xlabel('time (ms)')\n",
    "ax.set_ylabel('target')\n",
    "ax.set_yticks(.5+np.arange(len(ml.dataset.dataset.classes)))\n",
    "ax.set_yticklabels(ml.dataset.dataset.classes)\n",
    "N_frame = len(timings_frame)\n",
    "ax.set_xticks(np.arange(0, N_frame, N_frame//12))\n",
    "ax.set_xticklabels(['%.1f' % (timings_frame[int(i_f)]*1000) for i_f in  ax.get_xticks()])\n",
    "#ax.legend(loc='best')\n",
    "#plt.show() \n",
    "\n",
    "fname = 'figures/timing'\n",
    "for ext in ['.pdf', '.png']:\n",
    "    plt.savefig(fname + ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T13:27:31.033227Z",
     "start_time": "2018-10-19T13:25:37.779Z"
    }
   },
   "outputs": [],
   "source": [
    "toto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "source": [
    "# dynamical test : online detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T13:27:31.036120Z",
     "start_time": "2018-10-19T13:25:37.786Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def dyn_test(N_frame=32, startup_time=1., interframe_time=0., display=False):\n",
    "    try:\n",
    "        from gaze import FaceExtractor\n",
    "        F = FaceExtractor()\n",
    "        t = ml.dataset.transform\n",
    "\n",
    "        import time\n",
    "        time.sleep(startup_time)\n",
    "        et = Server()\n",
    "        timings_cv = []\n",
    "        timings_dlib = []\n",
    "        timings_torch = []\n",
    "        \n",
    "        for i in range(N_frame):            \n",
    "\n",
    "            t0 = time.time()\n",
    "            try:\n",
    "                t0 = time.time()\n",
    "                frame = et.cam.grab()[:, :, ::-1]\n",
    "                t1 = time.time()\n",
    "                timings_cv.append(t1-t0)\n",
    "                t0 = time.time()\n",
    "                img_face = F.face_extractor(frame)\n",
    "                t1 = time.time()\n",
    "                timings_dlib.append(t1-t0)\n",
    "                t0 = time.time()\n",
    "                pred = classify(img_face, t)\n",
    "                t1 = time.time()\n",
    "                timings_torch.append(t1-t0)\n",
    "                label = ml.dataset.dataset.classes[pred.argmax()]\n",
    "                if display:\n",
    "                    plt.imshow(img_face)\n",
    "                    plt.show() \n",
    "                    print('Prediction =', label)\n",
    "                else:\n",
    "                    clear_output()\n",
    "                    print(null)\n",
    "                    print(null)\n",
    "                    print(targets[label])\n",
    "                    print(null)\n",
    "                    print(null)                    \n",
    "\n",
    "                print('Elapsed time =', '%0.3f' % ((time.time()-t0)*1000), 'ms')\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "            time.sleep(interframe_time)\n",
    "            \n",
    "    finally:\n",
    "        et.close()\n",
    "        \n",
    "    for timings, label in [(timings_cv, 'openCV'), (timings_dlib, 'Dlib'), (timings_torch, 'torch')] :\n",
    "        timings = np.array(timings)*1000\n",
    "        print('For', label, ', timings in ms =', timings.mean(), '+/-', timings.std()) \n",
    "        \n",
    "dyn_test(display=False, interframe_time=1.)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T13:27:31.038499Z",
     "start_time": "2018-10-19T13:25:37.797Z"
    }
   },
   "outputs": [],
   "source": [
    "dyn_test(N_frame=8, display=False, interframe_time=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T13:27:31.041716Z",
     "start_time": "2018-10-19T13:25:37.804Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dyn_test(N_frame=8, display=True, interframe_time=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nteract": {
   "version": "0.8.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
