{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T13:25:37.760301Z",
     "start_time": "2018-10-19T13:25:37.707508Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T13:25:39.216923Z",
     "start_time": "2018-10-19T13:25:37.770286Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "Software versions": [
        {
         "module": "Python",
         "version": "3.6.5 64bit [GCC 4.2.1 Compatible Apple LLVM 9.1.0 (clang-902.0.39.2)]"
        },
        {
         "module": "IPython",
         "version": "7.0.1"
        },
        {
         "module": "OS",
         "version": "Darwin 18.0.0 x86_64 i386 64bit"
        },
        {
         "module": "numpy",
         "version": "1.15.2"
        },
        {
         "module": "dlib",
         "version": "19.16.0"
        },
        {
         "module": "matplotlib",
         "version": "3.0.0"
        },
        {
         "module": "imageio",
         "version": "2.4.1"
        },
        {
         "module": "gaze",
         "version": "The 'gaze' distribution was not found and is required by the application"
        },
        {
         "module": "torch",
         "version": "0.4.1"
        },
        {
         "module": "torchvision",
         "version": "0.2.1"
        }
       ]
      },
      "text/html": [
       "<table><tr><th>Software</th><th>Version</th></tr><tr><td>Python</td><td>3.6.5 64bit [GCC 4.2.1 Compatible Apple LLVM 9.1.0 (clang-902.0.39.2)]</td></tr><tr><td>IPython</td><td>7.0.1</td></tr><tr><td>OS</td><td>Darwin 18.0.0 x86_64 i386 64bit</td></tr><tr><td>numpy</td><td>1.15.2</td></tr><tr><td>dlib</td><td>19.16.0</td></tr><tr><td>matplotlib</td><td>3.0.0</td></tr><tr><td>imageio</td><td>2.4.1</td></tr><tr><td>gaze</td><td>The 'gaze' distribution was not found and is required by the application</td></tr><tr><td>torch</td><td>0.4.1</td></tr><tr><td>torchvision</td><td>0.2.1</td></tr><tr><td colspan='2'>Fri Oct 19 15:25:39 2018 CEST</td></tr></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{|l|l|}\\hline\n",
       "{\\bf Software} & {\\bf Version} \\\\ \\hline\\hline\n",
       "Python & 3.6.5 64bit [GCC 4.2.1 Compatible Apple LLVM 9.1.0 (clang-902.0.39.2)] \\\\ \\hline\n",
       "IPython & 7.0.1 \\\\ \\hline\n",
       "OS & Darwin 18.0.0 x86\\_64 i386 64bit \\\\ \\hline\n",
       "numpy & 1.15.2 \\\\ \\hline\n",
       "dlib & 19.16.0 \\\\ \\hline\n",
       "matplotlib & 3.0.0 \\\\ \\hline\n",
       "imageio & 2.4.1 \\\\ \\hline\n",
       "gaze & The 'gaze' distribution was not found and is required by the application \\\\ \\hline\n",
       "torch & 0.4.1 \\\\ \\hline\n",
       "torchvision & 0.2.1 \\\\ \\hline\n",
       "\\hline \\multicolumn{2}{|l|}{Fri Oct 19 15:25:39 2018 CEST} \\\\ \\hline\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "Software versions\n",
       "Python 3.6.5 64bit [GCC 4.2.1 Compatible Apple LLVM 9.1.0 (clang-902.0.39.2)]\n",
       "IPython 7.0.1\n",
       "OS Darwin 18.0.0 x86_64 i386 64bit\n",
       "numpy 1.15.2\n",
       "dlib 19.16.0\n",
       "matplotlib 3.0.0\n",
       "imageio 2.4.1\n",
       "gaze The 'gaze' distribution was not found and is required by the application\n",
       "torch 0.4.1\n",
       "torchvision 0.2.1\n",
       "Fri Oct 19 15:25:39 2018 CEST"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext version_information\n",
    "%version_information numpy, dlib, matplotlib, imageio, gaze, torch, torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T13:25:39.719305Z",
     "start_time": "2018-10-19T13:25:39.230160Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T13:25:39.762205Z",
     "start_time": "2018-10-19T13:25:39.724422Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters= {'dataset_folder': 'dataset', 'dataset_faces_folder': 'dataset_faces', 'batch_size': 8, 'test_batch_size': 1, 'size_test_set': 0.2, 'epochs': 40, 'do_adam': False, 'lr': 0.01, 'momentum': 0.05, 'no_cuda': True, 'num_processes': 1, 'seed': 42, 'log_interval': 0, 'fullsize': 75, 'crop': 64, 'size': 90, 'mean': 0.4, 'std': 0.3, 'conv1_dim': 9, 'conv1_kernel_size': 18, 'conv2_dim': 36, 'conv2_kernel_size': 14, 'conv1_bn_momentum': 0.5, 'conv2_bn_momentum': 0.5, 'dense_bn_momentum': 0.9, 'stride1': 2, 'stride2': 4, 'N_cv': 20, 'dimension': 30, 'verbose': 1}\n"
     ]
    }
   ],
   "source": [
    "from gaze import init\n",
    "args = init(no_cuda=True, verbose=1)\n",
    "print('Parameters=', args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T13:25:39.927091Z",
     "start_time": "2018-10-19T13:25:39.765414Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2221 sample images;  1777  to train 444 to test\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['blink', 'center', 'left', 'right']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gaze import Data\n",
    "d = Data(args)\n",
    "d.dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T13:25:40.015778Z",
     "start_time": "2018-10-19T13:25:39.930290Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty line\n",
      "ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«\n",
      "Fixation dot\n",
      "ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸ”µğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«\n",
      "label= left\n",
      "ğŸŒ«ğŸŒ«ğŸ”´ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«\n",
      "label= blink\n",
      "ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«â˜ ï¸ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«\n",
      "label= center\n",
      "ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸ”´ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«\n",
      "label= right\n",
      "ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸŒ«ğŸ”´ğŸŒ«ğŸŒ«\n"
     ]
    }
   ],
   "source": [
    "targets = {}\n",
    "s_target = 'ğŸ”´'\n",
    "s_fixat = 'ğŸ”µ'\n",
    "s_distra = 'ğŸŒ«'\n",
    "s_blink = 'â˜ ï¸'\n",
    "\n",
    "N_dis = 30 # <<<<<<<<<<<< change to adapt to your notebook's width\n",
    "N_margin = 2\n",
    "\n",
    "targets['left'] = N_margin * s_distra + s_target + 2 * N_dis * s_distra + N_margin * s_distra\n",
    "\n",
    "targets['blink'] = N_margin * s_distra + N_dis * s_distra + s_blink + N_dis * s_distra + N_margin * s_distra\n",
    "\n",
    "targets['center'] = N_margin * s_distra + N_dis * s_distra + s_target + N_dis * s_distra + N_margin * s_distra\n",
    "\n",
    "targets['right'] = N_margin * s_distra + 2 * N_dis * s_distra + s_target + N_margin * s_distra\n",
    "\n",
    "print ('Empty line')\n",
    "null = N_margin * s_distra +  (2 * N_dis + 1) * s_distra + N_margin * s_distra\n",
    "print (null)\n",
    "print ('Fixation dot')\n",
    "center = N_margin * s_distra + N_dis * s_distra + s_fixat + N_dis * s_distra + N_margin * s_distra\n",
    "print (center)\n",
    "\n",
    "for label in targets.keys():\n",
    "    print('label=', label)\n",
    "    print (targets[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "source": [
    "# dynamical test : offline detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T13:25:42.588887Z",
     "start_time": "2018-10-19T13:25:40.018914Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/laurentperrinet/research/LeCheapEyeTracker/src/LeCheapEyeTracker/haarcascade_frontalface_default.xml\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from LeCheapEyeTracker.EyeTrackerServer import Server\n",
    "#from LeCheapEyeTracker.EyeTrackerClient import Client\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T13:25:42.658797Z",
     "start_time": "2018-10-19T13:25:42.591870Z"
    }
   },
   "outputs": [],
   "source": [
    "def grab(classes, N_frame=32, startup_time=1., interframe_time=0.3, random=False, display=False):\n",
    "    try:\n",
    "        import time\n",
    "        time.sleep(startup_time)\n",
    "        et = Server()\n",
    "        frame = et.cam.grab()[:, :, ::-1]\n",
    "        N_X, N_Y, three = frame.shape\n",
    "\n",
    "        frames = []\n",
    "        labels = []\n",
    "        timings_frame = []\n",
    "        \n",
    "        N_classes = len(classes)\n",
    "        timings_cv = []\n",
    "        i_choice_old = 42\n",
    "        \n",
    "        T0 = time.time()\n",
    "        for i in range(N_frame):\n",
    "            try:\n",
    "                t0 = time.time()\n",
    "                frames.append(et.cam.grab()[:, :, ::-1])\n",
    "                timings_frame.append(time.time()-T0)\n",
    "                t1 = time.time()\n",
    "                timings_cv.append(t1-t0)\n",
    "                \n",
    "                if display:\n",
    "                    plt.imshow(frames[i, ...])\n",
    "                    plt.show() \n",
    "                else:\n",
    "                    # presentation of stimulus\n",
    "                    if random:\n",
    "                        i_choice = np.random.randint(N_classes)\n",
    "                    else:\n",
    "                        i_choice = (i // int(N_frame/N_classes) + 1) % N_classes\n",
    "                    #label = list(targets.keys())[i_choice]\n",
    "                    label = classes[i_choice]\n",
    "                    labels.append(label)\n",
    "                    if not i_choice == i_choice_old:\n",
    "                        clear_output()\n",
    "                        print(null)\n",
    "                        print(null)\n",
    "                        print(targets[label])\n",
    "                        print(null)\n",
    "                        print(null)                    \n",
    "                        i_choice_old = i_choice\n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "            time.sleep(interframe_time)            \n",
    "    finally:\n",
    "        et.close()\n",
    "        \n",
    "    for timings, label in [(timings_cv, 'openCV')] :\n",
    "        timings = np.array(timings)*1000\n",
    "        print('For', label, ', timings in ms = %.3f' % timings.mean(), '+/- %.3f' % timings.std()) \n",
    "\n",
    "    return frames, labels, timings_frame\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T13:25:42.698811Z",
     "start_time": "2018-10-19T13:25:42.663091Z"
    }
   },
   "outputs": [],
   "source": [
    "filename = '/tmp/dump_frames.pkl'\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T13:25:43.162943Z",
     "start_time": "2018-10-19T13:25:42.703019Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(frames)= 200\n",
      "frames[0].shape= (480, 640, 3)\n",
      "timings_frame[:10]= [0.06694626808166504, 0.15369915962219238, 0.24228525161743164, 0.33193230628967285, 0.4058973789215088, 0.4933462142944336, 0.5717661380767822, 0.6604912281036377, 0.7374284267425537, 0.8259913921356201]\n",
      "timings_frame[-10:]= [15.899439334869385, 15.98871922492981, 16.065667152404785, 16.155076265335083, 16.23355722427368, 16.323066234588623, 16.39961814880371, 16.48927116394043, 16.56708312034607, 16.65637230873108]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open(filename, \"rb\") as f:\n",
    "        dic = pickle.load(f)\n",
    "        frames = dic['frames']\n",
    "        labels = dic['labels']\n",
    "        timings_frame = dic['timings_frame']\n",
    "except:\n",
    "    frames, labels, timings_frame = grab(d.dataset.classes, \n",
    "                                         N_frame=200, startup_time=1., interframe_time=0., display=False)        \n",
    "    with open(filename, \"wb\") as f:\n",
    "        pickle.dump({'frames':frames, 'labels':labels, 'timings_frame':timings_frame}, f)\n",
    "    \n",
    "print('len(frames)=', len(frames))\n",
    "print('frames[0].shape=', frames[0].shape)\n",
    "print('timings_frame[:10]=', timings_frame[:10])\n",
    "print('timings_frame[-10:]=', timings_frame[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T13:25:43.208682Z",
     "start_time": "2018-10-19T13:25:43.169137Z"
    }
   },
   "outputs": [],
   "source": [
    "#!rm {filename}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T13:26:26.527939Z",
     "start_time": "2018-10-19T13:25:43.215997Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Dlib , timings in ms = 210.5155611038208 +/- 51.5454902322891\n"
     ]
    }
   ],
   "source": [
    "def extract_faces(frames, do_bbox_once=False, display=False):\n",
    "    from gaze import FaceExtractor\n",
    "    F = FaceExtractor()\n",
    "    import time\n",
    "    timings_dlib = []\n",
    "\n",
    "    N_frame  = len(frames)\n",
    "    N_X, N_Y, three = frames[0].shape\n",
    "    from PIL import Image\n",
    "\n",
    "    img_faces = []\n",
    "    bbox = F.get_bbox(frames[0]) if do_bbox_once else None\n",
    "    \n",
    "    for i in range(N_frame):\n",
    "        if display:\n",
    "            plt.imshow(frames[i]/255)\n",
    "            plt.show() \n",
    "        t0 = time.time()\n",
    "        try:\n",
    "            img_face = F.face_extractor(frames[i], bbox=bbox)\n",
    "        except:\n",
    "            print('No face in frame#', i)\n",
    "        img_faces.append(img_face)\n",
    "        t1 = time.time()\n",
    "        timings_dlib.append(t1-t0)\n",
    "        if display:\n",
    "            plt.imshow(img_face)\n",
    "            plt.show() \n",
    "        \n",
    "    for timings, label in [(timings_dlib, 'Dlib')] :\n",
    "        timings = np.array(timings)*1000\n",
    "        print('For', label, ', timings in ms =', timings.mean(), '+/-', timings.std()) \n",
    "\n",
    "    return img_faces\n",
    "\n",
    "img_faces = extract_faces(frames)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "def classify(image, t):\n",
    "    from PIL import Image\n",
    "    image = Image.fromarray(image)#.astype('uint8'), 'RGB')\n",
    "    data = t(image)\n",
    "    data.unsqueeze_(0)\n",
    "    output = ml.model(data)    \n",
    "    return np.exp(output.data.numpy()[0, :].astype(np.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T13:26:26.586242Z",
     "start_time": "2018-10-19T13:26:26.531057Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2221 sample images;  1777  to train 444 to test\n"
     ]
    }
   ],
   "source": [
    "from gaze import ML\n",
    "ml = ML(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T13:26:26.650198Z",
     "start_time": "2018-10-19T13:26:26.590621Z"
    }
   },
   "outputs": [],
   "source": [
    "path = '_Regard_400.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T13:26:26.689370Z",
     "start_time": "2018-10-19T13:26:26.656017Z"
    }
   },
   "outputs": [],
   "source": [
    "path = '_Regard.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T13:27:31.019837Z",
     "start_time": "2018-10-19T13:26:26.710018Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Train Epoch:   0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected more than 1 value per channel when training, got input size [1, 30]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-73e072f15695>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/research/CatchTheEye/gaze.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, path, seed)\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training model...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#save the neural network state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model saved at'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/research/CatchTheEye/gaze.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, path, seed)\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Train Epoch'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0;31m# report classification results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_interval\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/research/CatchTheEye/gaze.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self, epoch, seed, rank)\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0;31m# Predict classes using images from the train set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m             \u001b[0;31m# Compute the loss based on the predictions and actual labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/research/CatchTheEye/gaze.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense_input_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense_bn_momentum\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense_bn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mACTIVATION\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             exponential_average_factor, self.eps)\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   1249\u001b[0m         \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Expected more than 1 value per channel when training, got input size {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m     return torch.batch_norm(\n\u001b[1;32m   1253\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected more than 1 value per channel when training, got input size [1, 30]"
     ]
    }
   ],
   "source": [
    "ml.train(path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T13:27:31.027952Z",
     "start_time": "2018-10-19T13:25:37.753Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def dyn_test(img_faces, labels, display=False, verbose=False):\n",
    "    import time\n",
    "    from PIL import Image\n",
    "    timings_torch = []\n",
    "    preds = []\n",
    "    for img_face, label in zip(img_faces, labels) :\n",
    "        t0 = time.time()\n",
    "        pred = ml.classify(img_face, ml.dataset.test_transform)\n",
    "        t1 = time.time()\n",
    "        timings_torch.append(t1-t0)\n",
    "        preds.append(pred)    \n",
    "        pred_label = ml.dataset.dataset.classes[pred.argmax()]\n",
    "        if verbose: print('Prediction =', pred_label, 'Shown label =', label)\n",
    "        if display:\n",
    "            plt.imshow(img_face)\n",
    "            plt.show() \n",
    "\n",
    "    for timings, label in [(timings_torch, 'torch')] :\n",
    "        timings = np.array(timings)*1000\n",
    "        print('For', label, ', timings in ms =', timings.mean(), '+/-', timings.std()) \n",
    "    return np.array(preds)\n",
    "        \n",
    "preds = dyn_test(img_faces, labels, display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T13:27:31.030625Z",
     "start_time": "2018-10-19T13:25:37.761Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=((16, 5)))\n",
    "ax = axs[0]\n",
    "x_label = np.array([-(l == 'left')  + (l == 'right') for l in labels])\n",
    "ax.plot(np.array(timings_frame)*1000, x_label, '--', lw=1, alpha=.5)\n",
    "p_b, p_c, p_l, p_r = preds[:, 0], preds[:, 1], preds[:, 2], preds[:, 3]\n",
    "ax.pcolor(np.array(timings_frame)*1000, np.array([-1, 1]), p_b[None,:], cmap=plt.get_cmap('binary'), alpha=.5)\n",
    "x_pred = 2 / np.pi * np.arctan2(p_r-p_l, p_c)\n",
    "#h_pred = (preds * np.log(preds)).sum(axis=1) / np.log(4)\n",
    "ax.plot(np.array(timings_frame)*1000, x_pred, lw=.5, alpha=.5)\n",
    "ax.scatter(np.array(timings_frame)*1000, x_pred, 14*(1-p_b), color='k')\n",
    "ax.set_xticklabels([])\n",
    "ax.set_ylabel('estimated position')\n",
    "ax.set_xlim(0, np.array(timings_frame).max()*1000 )\n",
    "ax.set_ylim(-1.05, 1.05)\n",
    "ax = axs[1]\n",
    "ax.pcolor(preds.T, cmap=plt.hot())\n",
    "label_num = [1*(l == 'center') + 2*(l == 'left')  + 3*(l == 'right') for l in labels]\n",
    "ax.plot(np.array(label_num)+.5, 'wo', ms=8)\n",
    "ax.plot(np.array(label_num)+.5, 'bo', ms=4)\n",
    "ax.set_xlabel('time (ms)')\n",
    "ax.set_ylabel('target')\n",
    "ax.set_yticks(.5+np.arange(len(ml.dataset.dataset.classes)))\n",
    "ax.set_yticklabels(ml.dataset.dataset.classes)\n",
    "N_frame = len(timings_frame)\n",
    "ax.set_xticks(np.arange(0, N_frame, N_frame//12))\n",
    "ax.set_xticklabels(['%.1f' % (timings_frame[int(i_f)]*1000) for i_f in  ax.get_xticks()])\n",
    "#ax.legend(loc='best')\n",
    "#plt.show() \n",
    "\n",
    "fname = 'figures/timing'\n",
    "for ext in ['.pdf', '.png']:\n",
    "    plt.savefig(fname + ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T13:27:31.033227Z",
     "start_time": "2018-10-19T13:25:37.779Z"
    }
   },
   "outputs": [],
   "source": [
    "toto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "source": [
    "# dynamical test : online detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T13:27:31.036120Z",
     "start_time": "2018-10-19T13:25:37.786Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def dyn_test(N_frame=32, startup_time=1., interframe_time=0., display=False):\n",
    "    try:\n",
    "        from gaze import FaceExtractor\n",
    "        F = FaceExtractor()\n",
    "        t = ml.dataset.transform\n",
    "\n",
    "        import time\n",
    "        time.sleep(startup_time)\n",
    "        et = Server()\n",
    "        timings_cv = []\n",
    "        timings_dlib = []\n",
    "        timings_torch = []\n",
    "        \n",
    "        for i in range(N_frame):            \n",
    "\n",
    "            t0 = time.time()\n",
    "            try:\n",
    "                t0 = time.time()\n",
    "                frame = et.cam.grab()[:, :, ::-1]\n",
    "                t1 = time.time()\n",
    "                timings_cv.append(t1-t0)\n",
    "                t0 = time.time()\n",
    "                img_face = F.face_extractor(frame)\n",
    "                t1 = time.time()\n",
    "                timings_dlib.append(t1-t0)\n",
    "                t0 = time.time()\n",
    "                pred = classify(img_face, t)\n",
    "                t1 = time.time()\n",
    "                timings_torch.append(t1-t0)\n",
    "                label = ml.dataset.dataset.classes[pred.argmax()]\n",
    "                if display:\n",
    "                    plt.imshow(img_face)\n",
    "                    plt.show() \n",
    "                    print('Prediction =', label)\n",
    "                else:\n",
    "                    clear_output()\n",
    "                    print(null)\n",
    "                    print(null)\n",
    "                    print(targets[label])\n",
    "                    print(null)\n",
    "                    print(null)                    \n",
    "\n",
    "                print('Elapsed time =', '%0.3f' % ((time.time()-t0)*1000), 'ms')\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "            time.sleep(interframe_time)\n",
    "            \n",
    "    finally:\n",
    "        et.close()\n",
    "        \n",
    "    for timings, label in [(timings_cv, 'openCV'), (timings_dlib, 'Dlib'), (timings_torch, 'torch')] :\n",
    "        timings = np.array(timings)*1000\n",
    "        print('For', label, ', timings in ms =', timings.mean(), '+/-', timings.std()) \n",
    "        \n",
    "dyn_test(display=False, interframe_time=1.)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T13:27:31.038499Z",
     "start_time": "2018-10-19T13:25:37.797Z"
    }
   },
   "outputs": [],
   "source": [
    "dyn_test(N_frame=8, display=False, interframe_time=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T13:27:31.041716Z",
     "start_time": "2018-10-19T13:25:37.804Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dyn_test(N_frame=8, display=True, interframe_time=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nteract": {
   "version": "0.8.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
