{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gaze import init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optional arguments :\n",
      "\n",
      "\tdataset_folder\t\t- description --> Dataset Folder\n",
      "\t\t\t\t- default --> dataset\n",
      "\n",
      "\tdataset_faces_folder\t- description --> Dataset Faces Folder\n",
      "\t\t\t\t- default --> dataset_faces\n",
      "\n",
      "\tbatch_size\t\t- description --> batch_size\n",
      "\t\t\t\t- default --> 16\n",
      "\n",
      "\tno_cuda\t\t\t- description --> No cuda\n",
      "\t\t\t\t- default --> False\n",
      "\n",
      "\ttest_batch_size\t\t- description --> Test Batch Size\n",
      "\t\t\t\t- default --> 16\n",
      "\n",
      "\tsize_test_set\t\t- description --> Size Test Set\n",
      "\t\t\t\t- default --> 0.2\n",
      "\n",
      "\tdo_adam\t\t\t- description --> Do Adam\n",
      "\t\t\t\t- default --> False\n",
      "\n",
      "\tepochs\t\t\t- description --> Epochs\n",
      "\t\t\t\t- default --> 40\n",
      "\n",
      "\tlr\t\t\t- description --> LR\n",
      "\t\t\t\t- default --> 0.01\n",
      "\n",
      "\tmomentum\t\t- description --> momentum\n",
      "\t\t\t\t- default --> 0.05\n",
      "\n",
      "\tnum_processes\t\t- description --> num_processes\n",
      "\t\t\t\t- default --> 1\n",
      "\n",
      "\tseed\t\t\t- description --> seed\n",
      "\t\t\t\t- default --> 42\n",
      "\n",
      "\tlog_interval\t\t- description --> period with which we report results for the loss\n",
      "\t\t\t\t- default --> 0\n",
      "\n",
      "\tfullsize\t\t- description --> size at the input of the transforms pipeline\n",
      "\t\t\t\t- default --> 75\n",
      "\n",
      "\tcrop\t\t\t- description --> crop\n",
      "\t\t\t\t- default --> 75\n",
      "\n",
      "\tsize\t\t\t- description --> size at the output of the transforms pipeline\n",
      "\t\t\t\t- default --> 40\n",
      "\n",
      "\tmean\t\t\t- description --> mean\n",
      "\t\t\t\t- default --> 0.4\n",
      "\n",
      "\tstd\t\t\t- description --> std\n",
      "\t\t\t\t- default --> 0.3\n",
      "\n",
      "\tconv1_dim\t\t- description --> conv1_dim\n",
      "\t\t\t\t- default --> 9\n",
      "\n",
      "\tconv1_kernel_size\t- description --> conv1_kernel_size\n",
      "\t\t\t\t- default --> 8\n",
      "\n",
      "\tconv1_bn_momentum\t- description --> conv1_bn_momentum\n",
      "\t\t\t\t- default --> 0.5\n",
      "\n",
      "\tconv2_kernel_size\t- description --> conv2_kernel_size\n",
      "\t\t\t\t- default --> 12\n",
      "\n",
      "\tconv2_dim\t\t- description --> conv2_dim\n",
      "\t\t\t\t- default --> 36\n",
      "\n",
      "\tconv2_bn_momentum\t- description --> conv2_bn_momentum\n",
      "\t\t\t\t- default --> 0.5\n",
      "\n",
      "\tdense_bn_momentum\t- description --> dense_bn_momentum\n",
      "\t\t\t\t- default --> 0.5\n",
      "\n",
      "\tdimension\t\t- description --> dimension\n",
      "\t\t\t\t- default --> 30\n",
      "\n",
      "\tverbose\t\t\t- description --> verbose\n",
      "\t\t\t\t- default --> False\n",
      "\n",
      "\tstride1\t\t\t- description --> stride1\n",
      "\t\t\t\t- default --> 2\n",
      "\n",
      "\tstride2\t\t\t- description --> stride2\n",
      "\t\t\t\t- default --> 4\n",
      "\n",
      "\tN_cv\t\t\t- description --> N_cv\n",
      "\t\t\t\t- default --> 20\n",
      "\n",
      "\tactivation\t\t- description --> 'relu', 'tanh', or 'softmax'\n",
      "\t\t\t\t- default --> relu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lala=init(print_help=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from LeCheapEyeTracker.EyeTrackerServer import FaceExtractor\n",
    "import os\n",
    "import torch\n",
    "torch.set_default_tensor_type('torch.FloatTensor')\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# TODO add a args.activation str variable\n",
    "ACTIVATION = F.relu\n",
    "# ACTIVATION = torch.tanh\n",
    "# ACTIVATION = F.softmax\n",
    "\n",
    "class Data:\n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "\n",
    "        # making sure that all folders exist\n",
    "        try:\n",
    "            os.mkdir(self.args.dataset_faces_folder)\n",
    "        except:\n",
    "            pass\n",
    "        self.classes = ['blink', 'center', 'left', 'right'] # TODO : get from the full dataset\n",
    "        for label in self.classes:\n",
    "            try:\n",
    "                os.mkdir(os.path.join(self.args.dataset_faces_folder, label))\n",
    "                print('Creating folder ', os.path.join(self.args.dataset_faces_folder, label))\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        # GPU boilerplate\n",
    "        if self.args.verbose:\n",
    "            if not self.args.no_cuda and not torch.cuda.is_available():\n",
    "                print('Trying to load cuda, but it is not available')\n",
    "        self.args.no_cuda = self.args.no_cuda or not torch.cuda.is_available()\n",
    "        #if self.args.verbose:\n",
    "        #    print('no cuda?', self.args.no_cuda)\n",
    "        kwargs = {'num_workers': 1, 'pin_memory': True} if not args.no_cuda else {'num_workers': 1}\n",
    "        kwargs.update(drop_last=True)\n",
    "        # https://pytorch.org/docs/master/torchvision/transforms.html#torchvision.transforms.Resize\n",
    "        # Resize the input PIL Image to the given size.\n",
    "        tr = transforms.Resize((args.fullsize, 4*args.fullsize))\n",
    "        tcc = transforms.CenterCrop((args.crop, 4*args.crop))\n",
    "        tr2 = transforms.Resize((args.size, 4*args.size))\n",
    "        ttt= transforms.ToTensor()\n",
    "        tn = transforms.Normalize(mean=[args.mean]*3, std=[args.std]*3)\n",
    "\n",
    "        self.train_transform = transforms.Compose([\n",
    "            tr,\n",
    "            # https://pytorch.org/docs/master/torchvision/transforms.html#torchvision.transforms.RandomAffine\n",
    "            #transforms.RandomAffine(degrees=5, scale=(.9, 1.1), shear=3, resample=False, fillcolor=0),\n",
    "            #transforms.RandomAffine(degrees=2.5, shear=1., resample=False, fillcolor=0),\n",
    "            tcc, tr2, ttt, tn,\n",
    "            ])\n",
    "\n",
    "        self.test_transform = transforms.Compose([\n",
    "            tr,\n",
    "            tcc, tr2, ttt, tn,\n",
    "            ])\n",
    "        try:\n",
    "            self.dataset = ImageFolder(self.args.dataset_faces_folder, self.train_transform)\n",
    "            #self.train_loader = torch.utils.data.DataLoader(self.dataset, batch_size=args.batch_size, shuffle=True, num_workers=1)\n",
    "            #self.test_loader = torch.utils.data.DataLoader(self.dataset, batch_size=args.test_batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "            # https://gist.github.com/kevinzakka/d33bf8d6c7f06a9d8c76d97a7879f5cb\n",
    "            num_train = len(self.dataset)\n",
    "            # indices = list(range(num_train))\n",
    "            split = int(np.floor(self.args.size_test_set * num_train))\n",
    "            if self.args.verbose:\n",
    "                print('Found', num_train, 'sample images; ', num_train-split, ' to train', split, 'to test')\n",
    "\n",
    "            # N-batch_size, C-num_channels , H-height, W-width\n",
    "            from torch.utils.data import random_split\n",
    "            train_dataset, test_dataset = random_split(self.dataset, [num_train-split, split])\n",
    "\n",
    "            self.train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=self.args.batch_size, **kwargs)\n",
    "            self.test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=self.args.test_batch_size, **kwargs)\n",
    "            self.classes = self.dataset.classes #'blink', 'left ', 'right', ' fix '\n",
    "        except Exception as e:\n",
    "            print('Could not load dataset', e)\n",
    "\n",
    "    def show(self, noise_level=.4, nrow=8, transpose=True):\n",
    "\n",
    "        images, foo = next(iter(self.train_loader))\n",
    "        # https://pytorch.org/docs/stable/torchvision/utils.html#torchvision.utils.make_grid\n",
    "        from torchvision.utils import make_grid\n",
    "        npimg = make_grid(images, normalize=True, nrow=nrow).numpy()\n",
    "        import matplotlib.pyplot as plt\n",
    "        fig, ax = plt.subplots(figsize=((8, 5)))\n",
    "        import numpy as np\n",
    "        if transpose:\n",
    "            ax.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "        else:\n",
    "            ax.imshow(npimg)\n",
    "        plt.setp(ax, xticks=[], yticks=[])\n",
    "\n",
    "        return fig, ax\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        # TODO : rajouter la position de la tete comme entrée\n",
    "        super(Net, self).__init__()\n",
    "        self.args = args\n",
    "        # data is in the format (N, C, H, W)\n",
    "        self.conv1 = nn.Conv2d(3, args.conv1_dim, kernel_size=args.conv1_kernel_size) # TODO add , padding_mode=args.padding_mode\n",
    "        self.conv1_bn = nn.BatchNorm2d(args.conv1_dim, momentum=1-args.conv1_bn_momentum)\n",
    "        padding1 = args.conv1_kernel_size - 1 # total padding in layer 1 (before max pooling)\n",
    "        # https://pytorch.org/docs/stable/nn.html#torch.nn.MaxPool2d\n",
    "        out_height_1 = (args.size - padding1 - args.stride1) // args.stride1 + 1\n",
    "        out_width_1 = (4*args.size - padding1 - args.stride1) // args.stride1 + 1\n",
    "        # TODO : self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(args.conv1_dim, args.conv2_dim, kernel_size=args.conv2_kernel_size)\n",
    "        self.conv2_bn = nn.BatchNorm2d(args.conv2_dim, momentum=1-args.conv2_bn_momentum)\n",
    "        padding2 = args.conv2_kernel_size - 1 # total padding in layer 2\n",
    "        out_height_2 = (out_height_1 - padding2 - args.stride2) // args.stride2 + 1\n",
    "        out_width_2 = (out_width_1 - padding2 - args.stride2) // args.stride2 + 1\n",
    "        fc1_dim = (out_width_2*out_height_2) * args.conv2_dim\n",
    "        self.dense_1 = nn.Linear(fc1_dim, args.dimension)\n",
    "        # This momentum argument is different from one used in optimizer classes and the conventional notion of momentum. Mathematically, the update rule for running statistics here is x̂ new=(1−momentum)×x̂ +momemtum×xt, where x̂  is the estimated statistic and xt is the new observed value.\n",
    "        self.dense_bn = nn.BatchNorm1d(args.dimension, momentum=1-args.dense_bn_momentum)\n",
    "        self.dense_2 = nn.Linear(args.dimension, len(self.args.classes))\n",
    "        self.dense_input_size = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        if self.args.conv1_bn_momentum>0: x = self.conv1_bn(x)\n",
    "        x = ACTIVATION(F.max_pool2d(x, kernel_size=[self.args.stride1, self.args.stride1]))#, stride=[self.args.stride1, self.args.stride1]))\n",
    "        # x = ACTIVATION(F.max_pool2d(self.conv2_drop(self.conv2(x)), kernel_size=[self.args.stride2, self.args.stride2]))#, stride=[self.args.stride2, self.args.stride2]))\n",
    "        x = self.conv2(x)\n",
    "        if self.args.conv2_bn_momentum>0:x = self.conv2_bn(x)\n",
    "        x = ACTIVATION(F.max_pool2d(x, kernel_size=[self.args.stride2, self.args.stride2]))#, stride=[self.args.stride2, self.args.stride2]))\n",
    "        if self.dense_input_size is None: self.dense_input_size= self.num_flat_features(x)\n",
    "        x = x.view(-1, self.dense_input_size)\n",
    "        x = self.dense_1(x)\n",
    "        if self.args.dense_bn_momentum>0: x = self.dense_bn(x)\n",
    "        x = ACTIVATION(x)\n",
    "        x = self.dense_2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "class ML():\n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "        # GPU boilerplate\n",
    "        self.args.no_cuda = self.args.no_cuda or not torch.cuda.is_available()\n",
    "        # if self.args.verbose: print('cuda?', not self.args.no_cuda)\n",
    "        self.device = torch.device(\"cpu\" if self.args.no_cuda else \"cuda\")\n",
    "        torch.manual_seed(self.args.seed)\n",
    "        # DATA\n",
    "        self.dataset = Data(self.args)\n",
    "        self.args.classes = self.dataset.classes\n",
    "        # MODEL\n",
    "        self.model = Net(self.args).to(self.device)\n",
    "        if not self.args.no_cuda:\n",
    "            # print('doing cuda')\n",
    "            torch.cuda.manual_seed(self.args.seed)\n",
    "            self.model.cuda()\n",
    "\n",
    "        if self.args.do_adam:\n",
    "            # see https://heartbeat.fritz.ai/basics-of-image-classification-with-pytorch-2f8973c51864\n",
    "            self.optimizer = optim.Adam(self.model.parameters(),\n",
    "                                    lr=self.args.lr, betas=(1.-self.args.momentum, 0.999), eps=1e-8)\n",
    "        else:\n",
    "            self.optimizer = optim.SGD(self.model.parameters(),\n",
    "                                    lr=self.args.lr, momentum=self.args.momentum)\n",
    "    # def forward(self, img):\n",
    "    #     # normalize img\n",
    "    #     return (img - self.mean) / self.std\n",
    "\n",
    "    def train(self, path=None, seed=None):\n",
    "        if not path is None:\n",
    "            # using a data_cache\n",
    "            if os.path.isfile(path):\n",
    "                self.model.load_state_dict(torch.load(path))\n",
    "                print('Loading file', path)\n",
    "            else:\n",
    "                print('Training model...')\n",
    "                self.train(path=None, seed=seed)\n",
    "                torch.save(self.model.state_dict(), path) #save the neural network state\n",
    "                print('Model saved at', path)\n",
    "        else:\n",
    "            # cosmetics\n",
    "            try:\n",
    "                from tqdm import tqdm\n",
    "                #from tqdm import tqdm_notebook as tqdm\n",
    "                verbose = 1\n",
    "            except ImportError:\n",
    "                verbose = 0\n",
    "            if self.args.verbose == 0 or verbose == 0:\n",
    "                def tqdm(x, desc=None):\n",
    "                    if desc is not None: print(desc)\n",
    "                    return x\n",
    "\n",
    "            # setting up training\n",
    "            if seed is None:\n",
    "                seed = self.args.seed\n",
    "            self.model.train()\n",
    "            for epoch in tqdm(range(1, self.args.epochs + 1), desc='Train Epoch' if self.args.verbose else None):\n",
    "                loss = self.train_epoch(epoch, seed, rank=0)\n",
    "                # report classification results\n",
    "                if self.args.verbose and self.args.log_interval>0:\n",
    "                    if epoch % self.args.log_interval == 0:\n",
    "                        status_str = '\\tTrain Epoch: {} \\t Loss: {:.6f}'.format(epoch, loss)\n",
    "                        try:\n",
    "                            from tqdm import tqdm\n",
    "                            tqdm.write(status_str)\n",
    "                        except Exception as e:\n",
    "                            print(e)\n",
    "                            print(status_str)\n",
    "            self.model.eval()\n",
    "\n",
    "    def train_epoch(self, epoch, seed, rank=0):\n",
    "        torch.manual_seed(seed + epoch + rank*self.args.epochs)\n",
    "        for batch_idx, (data, target) in enumerate(self.dataset.train_loader):\n",
    "            data, target = data.to(self.device), target.to(self.device)\n",
    "            # Clear all accumulated gradients\n",
    "            self.optimizer.zero_grad()\n",
    "            # Predict classes using images from the train set\n",
    "            output = self.model(data)\n",
    "            # Compute the loss based on the predictions and actual labels\n",
    "            loss = F.nll_loss(output, target, reduction='sum')\n",
    "            # Backpropagate the loss\n",
    "            loss.backward()\n",
    "            # Adjust parameters according to the computed gradients\n",
    "            self.optimizer.step()\n",
    "        return loss.item()\n",
    "\n",
    "    def classify(self, image, t):\n",
    "        from PIL import Image\n",
    "        image = Image.fromarray(image)#.astype('uint8'), 'RGB')\n",
    "        data = t(image).unsqueeze(0)\n",
    "        # data.requires_grad = False\n",
    "        self.model.eval()\n",
    "        #output = self.model(data)\n",
    "        #return np.exp(output.data.numpy()[0, :].astype(np.float))\n",
    "        output = self.model(data.cuda())\n",
    "        return np.exp(output.cpu().data.numpy()[0, :].astype(np.float))\n",
    "\n",
    "    def test(self, dataloader=None):\n",
    "        if dataloader is None:\n",
    "            dataloader = self.dataset.test_loader\n",
    "        self.model.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        for data, target in dataloader:\n",
    "            data, target = data.to(self.device), target.to(self.device)\n",
    "            output = self.model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.data.view_as(pred)).long().cpu().sum()\n",
    "\n",
    "        test_loss /= len(dataloader.dataset)\n",
    "\n",
    "        if self.args.log_interval>0:\n",
    "            print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            test_loss, correct, len(dataloader.dataset),\n",
    "            100. * correct / len(dataloader.dataset)))\n",
    "        return correct.numpy() / len(dataloader.dataset)\n",
    "\n",
    "    def show(self, gamma=.5, noise_level=.4, transpose=True, only_wrong=False):\n",
    "        for idx, (data, target) in enumerate(self.dataset.test_loader):\n",
    "            #data, target = next(iter(self.dataset.test_loader))\n",
    "            data, target = data.to(self.device), target.to(self.device)\n",
    "            output = self.model(data)\n",
    "            pred = output.data.max(1, keepdim=False)[1] # get the index of the max log-probability\n",
    "            #if only_wrong and not pred == target :\n",
    "            if only_wrong and not all(pred) == all(target) :\n",
    "                #print(target, self.dataset.dataset.imgs[self.dataset.test_loader.dataset.indices[idx]])\n",
    "                print('target:' + ' '.join('%5s' % self.dataset.dataset.classes[j] for j in target))\n",
    "                print('pred  :' + ' '.join('%5s' % self.dataset.dataset.classes[j] for j in pred))\n",
    "                #print(target, pred)\n",
    "\n",
    "                from torchvision.utils import make_grid\n",
    "                npimg = make_grid(data, normalize=True).numpy()\n",
    "                import matplotlib.pyplot as plt\n",
    "                fig, ax = plt.subplots(figsize=((13, 5)))\n",
    "                import numpy as np\n",
    "                if transpose:\n",
    "                    ax.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "                else:\n",
    "                    ax.imshow(npimg)\n",
    "                plt.setp(ax, xticks=[], yticks=[])\n",
    "\n",
    "                return fig, ax\n",
    "            else:\n",
    "                return None, None\n",
    "\n",
    "\n",
    "    def main(self, path=None, seed=None):\n",
    "        self.train(path=path, seed=seed)\n",
    "        Accuracy = self.test()\n",
    "        return Accuracy\n",
    "\n",
    "\n",
    "import time\n",
    "class MetaML:\n",
    "    def __init__(self, args, base = 2, N_scan = 9, tag='', verbose=0, log_interval=0):\n",
    "        self.args = args\n",
    "        self.seed = args.seed\n",
    "\n",
    "        self.base = base\n",
    "        self.N_scan = N_scan\n",
    "        self.tag = tag\n",
    "        self.default = dict(verbose=verbose, log_interval=log_interval)\n",
    "\n",
    "    def test(self, args, seed):\n",
    "        # makes a loop for the cross-validation of results\n",
    "        Accuracy = []\n",
    "        for i_cv in range(self.args.N_cv):\n",
    "            ml = ML(args)\n",
    "            ml.train(seed=seed + i_cv)\n",
    "            Accuracy.append(ml.test())\n",
    "        return np.array(Accuracy)\n",
    "\n",
    "    def protocol(self, args, seed):\n",
    "        t0 = time.time()\n",
    "        Accuracy = self.test(args, seed)\n",
    "        t1 = time.time() - t0\n",
    "        Accuracy = np.hstack((Accuracy, [t1]))\n",
    "        return Accuracy\n",
    "\n",
    "    def scan(self, parameter, values):\n",
    "        import os\n",
    "        try:\n",
    "            os.mkdir('_tmp_scanning')\n",
    "        except:\n",
    "            pass\n",
    "        print('scanning over', parameter, '=', values)\n",
    "        seed = self.seed\n",
    "        Accuracy = {}\n",
    "        for value in values:\n",
    "            if isinstance(value, int):\n",
    "                value_str = str(value)\n",
    "            else:\n",
    "                value_str = '%.3f' % value\n",
    "            path = '_tmp_scanning/' + parameter + '_' + self.tag + '_' + value_str.replace('.', '_') + '.npy'\n",
    "            print ('For parameter', parameter, '=', value_str, ', ', end=\" \")\n",
    "            if not(os.path.isfile(path + '_lock')):\n",
    "                if not(os.path.isfile(path)):\n",
    "                    open(path + '_lock', 'w').close()\n",
    "                    try:\n",
    "                        args = easydict.EasyDict(self.args.copy())\n",
    "                        args[parameter] = value\n",
    "                        Accuracy[value] = self.protocol(args, seed)\n",
    "                        np.save(path, Accuracy[value])\n",
    "                        os.remove(path + '_lock')\n",
    "                    except Exception as e:\n",
    "                        print('Failed with error', e)\n",
    "                else:\n",
    "                    Accuracy[value] = np.load(path)\n",
    "\n",
    "                try:\n",
    "                    print('Accuracy={:.1f}% +/- {:.1f}%'.format(Accuracy[value][:-1].mean()*100, Accuracy[value][:-1].std()*100),\n",
    "                  ' in {:.1f} seconds'.format(Accuracy[value][-1]))\n",
    "                except Exception as e:\n",
    "                    print('Failed with error', e)\n",
    "\n",
    "            else:\n",
    "                print(' currently locked with ', path + '_lock')\n",
    "            seed += 1\n",
    "        return Accuracy\n",
    "\n",
    "    def parameter_scan(self, parameter, display=False):\n",
    "        if parameter in ['momentum', 'conv1_bn_momentum', 'conv2_bn_momentum', 'dense_bn_momentum']:\n",
    "            values = np.linspace(0, 1, self.N_scan, endpoint=True)\n",
    "        else:\n",
    "            values = self.args[parameter] * np.logspace(-1, 1, self.N_scan, base=self.base)\n",
    "        if isinstance(self.args[parameter], int):\n",
    "            # print('integer detected') # DEBUG\n",
    "            values =  [int(k) for k in values]\n",
    "        Accuracy = self.scan(parameter, values)\n",
    "        if display:\n",
    "            fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "        return Accuracy\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import os\n",
    "    filename = 'figures/accuracy.pdf'\n",
    "    if False : #not os.path.exists(filename) :\n",
    "        args = init(verbose=0, log_interval=0, epochs=20)\n",
    "        from gaze import MetaML\n",
    "        mml = MetaML(args)\n",
    "        Accuracy = mml.protocol(args, 42)\n",
    "        print('Accuracy', Accuracy[:-1].mean(), '+/-', Accuracy[:-1].std())\n",
    "        import numpy as np\n",
    "        import matplotlib.pyplot as plt\n",
    "        fig, ax = plt.subplots(figsize=((8, 5)))\n",
    "        n, bins, patches = ax.hist(Accuracy[:-1]*100, bins=np.linspace(0, 100, 100), alpha=.4)\n",
    "        ax.vlines(np.median(Accuracy[:-1])*100, 0, n.max(), 'g', linestyles='dashed', label='median')\n",
    "        ax.vlines(25, 0, n.max(), 'r', linestyles='dashed', label='chance level')\n",
    "        ax.vlines(100, 0, n.max(), 'k', label='max')\n",
    "        ax.set_xlabel('Accuracy (%)')\n",
    "        ax.set_ylabel('Smarts')\n",
    "        ax.legend(loc='best')\n",
    "        plt.show()\n",
    "        plt.savefig(filename)\n",
    "        plt.savefig(filename.replace('.pdf', '.png'))\n",
    "\n",
    "    print(50*'-')\n",
    "    print(' parameter scan')\n",
    "    print(50*'-')\n",
    "\n",
    "    if False :\n",
    "        print(50*'-')\n",
    "        print('Default parameters')\n",
    "        print(50*'-')\n",
    "        args = init(verbose=0, log_interval=0)\n",
    "        ml = ML(args)\n",
    "        ml.main()\n",
    "    if False :\n",
    "        args = init(verbose=0, log_interval=0)\n",
    "        mml = MetaML(args)\n",
    "        if torch.cuda.is_available():\n",
    "            mml.scan('no_cuda', [True, False])\n",
    "        else:\n",
    "            mml.scan('no_cuda', [True])\n",
    "\n",
    "    # for base in [2]:#, 8]:\n",
    "    for base in [2, 8]:\n",
    "        print(50*'-')\n",
    "        print(' base=', base)\n",
    "        print(50*'-')\n",
    "\n",
    "        print(50*'-')\n",
    "        print(' parameter scan : data')\n",
    "        print(50*'-')\n",
    "        args = init(verbose=0, log_interval=0)\n",
    "        mml = MetaML(args, base=base)\n",
    "        for parameter in ['size', 'fullsize', 'crop', 'mean', 'std']:\n",
    "            mml.parameter_scan(parameter)\n",
    "\n",
    "        print(50*'-')\n",
    "        args = init(verbose=0, log_interval=0)\n",
    "        mml = MetaML(args)\n",
    "        print(' parameter scan : network')\n",
    "        print(50*'-')\n",
    "        for parameter in ['conv1_kernel_size',\n",
    "                          'conv1_dim',\n",
    "                          'conv1_bn_momentum',\n",
    "                          'conv2_kernel_size',\n",
    "                          'conv2_dim',\n",
    "                          'conv2_bn_momentum',\n",
    "                          'stride1', 'stride2',\n",
    "                          'dense_bn_momentum',\n",
    "                          'dimension']:\n",
    "            mml.parameter_scan(parameter)\n",
    "\n",
    "        args = init(verbose=0, log_interval=0)\n",
    "        mml = MetaML(args, base=base)\n",
    "        print(' parameter scan : learning ')\n",
    "        print(50*'-')\n",
    "        print('Using SGD')\n",
    "        print(50*'-')\n",
    "        for parameter in ['lr', 'momentum', 'batch_size', 'epochs']:\n",
    "            mml.parameter_scan(parameter)\n",
    "        print(50*'-')\n",
    "        print('Using ADAM')\n",
    "        print(50*'-')\n",
    "        args = init(verbose=0, log_interval=0, do_adam=True)\n",
    "        mml = MetaML(args, tag='adam')\n",
    "        for parameter in ['lr', 'momentum', 'batch_size', 'epochs']:\n",
    "            mml.parameter_scan(parameter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from LeCheapEyeTracker.EyeTrackerServer import FaceExtractor\n",
    "import os\n",
    "import torch\n",
    "torch.set_default_tensor_type('torch.FloatTensor')\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# TODO add a args.activation str variable\n",
    "ACTIVATION = F.relu\n",
    "# ACTIVATION = torch.tanh\n",
    "# ACTIVATION = F.softmax\n",
    "\n",
    "class Data:\n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "\n",
    "        # making sure that all folders exist\n",
    "        try:\n",
    "            os.mkdir(self.args.dataset_faces_folder)\n",
    "        except:\n",
    "            pass\n",
    "        self.classes = ['blink', 'center', 'left', 'right'] # TODO : get from the full dataset\n",
    "        for label in self.classes:\n",
    "            try:\n",
    "                os.mkdir(os.path.join(self.args.dataset_faces_folder, label))\n",
    "                print('Creating folder ', os.path.join(self.args.dataset_faces_folder, label))\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        # GPU boilerplate\n",
    "        if self.args.verbose:\n",
    "            if not self.args.no_cuda and not torch.cuda.is_available():\n",
    "                print('Trying to load cuda, but it is not available')\n",
    "        self.args.no_cuda = self.args.no_cuda or not torch.cuda.is_available()\n",
    "        #if self.args.verbose:\n",
    "        #    print('no cuda?', self.args.no_cuda)\n",
    "        kwargs = {'num_workers': 1, 'pin_memory': True} if not args.no_cuda else {'num_workers': 1}\n",
    "        kwargs.update(drop_last=True)\n",
    "        # https://pytorch.org/docs/master/torchvision/transforms.html#torchvision.transforms.Resize\n",
    "        # Resize the input PIL Image to the given size.\n",
    "        tr = transforms.Resize((args.fullsize, 4*args.fullsize))\n",
    "        tcc = transforms.CenterCrop((args.crop, 4*args.crop))\n",
    "        tr2 = transforms.Resize((args.size, 4*args.size))\n",
    "        ttt= transforms.ToTensor()\n",
    "        tn = transforms.Normalize(mean=[args.mean]*3, std=[args.std]*3)\n",
    "\n",
    "        self.train_transform = transforms.Compose([\n",
    "            tr,\n",
    "            # https://pytorch.org/docs/master/torchvision/transforms.html#torchvision.transforms.RandomAffine\n",
    "            #transforms.RandomAffine(degrees=5, scale=(.9, 1.1), shear=3, resample=False, fillcolor=0),\n",
    "            #transforms.RandomAffine(degrees=2.5, shear=1., resample=False, fillcolor=0),\n",
    "            tcc, tr2, ttt, tn,\n",
    "            ])\n",
    "\n",
    "        self.test_transform = transforms.Compose([\n",
    "            tr,\n",
    "            tcc, tr2, ttt, tn,\n",
    "            ])\n",
    "        try:\n",
    "            self.dataset = ImageFolder(self.args.dataset_faces_folder, self.train_transform)\n",
    "            #self.train_loader = torch.utils.data.DataLoader(self.dataset, batch_size=args.batch_size, shuffle=True, num_workers=1)\n",
    "            #self.test_loader = torch.utils.data.DataLoader(self.dataset, batch_size=args.test_batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "            # https://gist.github.com/kevinzakka/d33bf8d6c7f06a9d8c76d97a7879f5cb\n",
    "            num_train = len(self.dataset)\n",
    "            # indices = list(range(num_train))\n",
    "            split = int(np.floor(self.args.size_test_set * num_train))\n",
    "            if self.args.verbose:\n",
    "                print('Found', num_train, 'sample images; ', num_train-split, ' to train', split, 'to test')\n",
    "\n",
    "            # N-batch_size, C-num_channels , H-height, W-width\n",
    "            from torch.utils.data import random_split\n",
    "            train_dataset, test_dataset = random_split(self.dataset, [num_train-split, split])\n",
    "\n",
    "            self.train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=self.args.batch_size, **kwargs)\n",
    "            self.test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=self.args.test_batch_size, **kwargs)\n",
    "            self.classes = self.dataset.classes #'blink', 'left ', 'right', ' fix '\n",
    "        except Exception as e:\n",
    "            print('Could not load dataset', e)\n",
    "\n",
    "    def show(self, noise_level=.4, nrow=8, transpose=True):\n",
    "\n",
    "        images, foo = next(iter(self.train_loader))\n",
    "        # https://pytorch.org/docs/stable/torchvision/utils.html#torchvision.utils.make_grid\n",
    "        from torchvision.utils import make_grid\n",
    "        npimg = make_grid(images, normalize=True, nrow=nrow).numpy()\n",
    "        import matplotlib.pyplot as plt\n",
    "        fig, ax = plt.subplots(figsize=((8, 5)))\n",
    "        import numpy as np\n",
    "        if transpose:\n",
    "            ax.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "        else:\n",
    "            ax.imshow(npimg)\n",
    "        plt.setp(ax, xticks=[], yticks=[])\n",
    "\n",
    "        return fig, ax\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        # TODO : rajouter la position de la tete comme entrée\n",
    "        super(Net, self).__init__()\n",
    "        self.args = args\n",
    "        # data is in the format (N, C, H, W)\n",
    "        self.conv1 = nn.Conv2d(3, args.conv1_dim, kernel_size=args.conv1_kernel_size) # TODO add , padding_mode=args.padding_mode\n",
    "        self.conv1_bn = nn.BatchNorm2d(args.conv1_dim, momentum=1-args.conv1_bn_momentum)\n",
    "        padding1 = args.conv1_kernel_size - 1 # total padding in layer 1 (before max pooling)\n",
    "        # https://pytorch.org/docs/stable/nn.html#torch.nn.MaxPool2d\n",
    "        out_height_1 = (args.size - padding1 - args.stride1) // args.stride1 + 1\n",
    "        out_width_1 = (4*args.size - padding1 - args.stride1) // args.stride1 + 1\n",
    "        # TODO : self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(args.conv1_dim, args.conv2_dim, kernel_size=args.conv2_kernel_size)\n",
    "        self.conv2_bn = nn.BatchNorm2d(args.conv2_dim, momentum=1-args.conv2_bn_momentum)\n",
    "        padding2 = args.conv2_kernel_size - 1 # total padding in layer 2\n",
    "        out_height_2 = (out_height_1 - padding2 - args.stride2) // args.stride2 + 1\n",
    "        out_width_2 = (out_width_1 - padding2 - args.stride2) // args.stride2 + 1\n",
    "        fc1_dim = (out_width_2*out_height_2) * args.conv2_dim\n",
    "        self.dense_1 = nn.Linear(fc1_dim, args.dimension)\n",
    "        # This momentum argument is different from one used in optimizer classes and the conventional notion of momentum. Mathematically, the update rule for running statistics here is x̂ new=(1−momentum)×x̂ +momemtum×xt, where x̂  is the estimated statistic and xt is the new observed value.\n",
    "        self.dense_bn = nn.BatchNorm1d(args.dimension, momentum=1-args.dense_bn_momentum)\n",
    "        self.dense_2 = nn.Linear(args.dimension, len(self.args.classes))\n",
    "        self.dense_input_size = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        if self.args.conv1_bn_momentum>0: x = self.conv1_bn(x)\n",
    "        x = ACTIVATION(F.max_pool2d(x, kernel_size=[self.args.stride1, self.args.stride1]))#, stride=[self.args.stride1, self.args.stride1]))\n",
    "        # x = ACTIVATION(F.max_pool2d(self.conv2_drop(self.conv2(x)), kernel_size=[self.args.stride2, self.args.stride2]))#, stride=[self.args.stride2, self.args.stride2]))\n",
    "        x = self.conv2(x)\n",
    "        if self.args.conv2_bn_momentum>0:x = self.conv2_bn(x)\n",
    "        x = ACTIVATION(F.max_pool2d(x, kernel_size=[self.args.stride2, self.args.stride2]))#, stride=[self.args.stride2, self.args.stride2]))\n",
    "        if self.dense_input_size is None: self.dense_input_size= self.num_flat_features(x)\n",
    "        x = x.view(-1, self.dense_input_size)\n",
    "        x = self.dense_1(x)\n",
    "        if self.args.dense_bn_momentum>0: x = self.dense_bn(x)\n",
    "        x = ACTIVATION(x)\n",
    "        x = self.dense_2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "class ML():\n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "        # GPU boilerplate\n",
    "        self.args.no_cuda = self.args.no_cuda or not torch.cuda.is_available()\n",
    "        # if self.args.verbose: print('cuda?', not self.args.no_cuda)\n",
    "        self.device = torch.device(\"cpu\" if self.args.no_cuda else \"cuda\")\n",
    "        torch.manual_seed(self.args.seed)\n",
    "        # DATA\n",
    "        self.dataset = Data(self.args)\n",
    "        self.args.classes = self.dataset.classes\n",
    "        # MODEL\n",
    "        self.model = Net(self.args).to(self.device)\n",
    "        if not self.args.no_cuda:\n",
    "            # print('doing cuda')\n",
    "            torch.cuda.manual_seed(self.args.seed)\n",
    "            self.model.cuda()\n",
    "\n",
    "        if self.args.do_adam:\n",
    "            # see https://heartbeat.fritz.ai/basics-of-image-classification-with-pytorch-2f8973c51864\n",
    "            self.optimizer = optim.Adam(self.model.parameters(),\n",
    "                                    lr=self.args.lr, betas=(1.-self.args.momentum, 0.999), eps=1e-8)\n",
    "        else:\n",
    "            self.optimizer = optim.SGD(self.model.parameters(),\n",
    "                                    lr=self.args.lr, momentum=self.args.momentum)\n",
    "    # def forward(self, img):\n",
    "    #     # normalize img\n",
    "    #     return (img - self.mean) / self.std\n",
    "\n",
    "    def train(self, path=None, seed=None):\n",
    "        if not path is None:\n",
    "            # using a data_cache\n",
    "            if os.path.isfile(path):\n",
    "                self.model.load_state_dict(torch.load(path))\n",
    "                print('Loading file', path)\n",
    "            else:\n",
    "                print('Training model...')\n",
    "                self.train(path=None, seed=seed)\n",
    "                torch.save(self.model.state_dict(), path) #save the neural network state\n",
    "                print('Model saved at', path)\n",
    "        else:\n",
    "            # cosmetics\n",
    "            try:\n",
    "                from tqdm import tqdm\n",
    "                #from tqdm import tqdm_notebook as tqdm\n",
    "                verbose = 1\n",
    "            except ImportError:\n",
    "                verbose = 0\n",
    "            if self.args.verbose == 0 or verbose == 0:\n",
    "                def tqdm(x, desc=None):\n",
    "                    if desc is not None: print(desc)\n",
    "                    return x\n",
    "\n",
    "            # setting up training\n",
    "            if seed is None:\n",
    "                seed = self.args.seed\n",
    "            self.model.train()\n",
    "            for epoch in tqdm(range(1, self.args.epochs + 1), desc='Train Epoch' if self.args.verbose else None):\n",
    "                loss = self.train_epoch(epoch, seed, rank=0)\n",
    "                # report classification results\n",
    "                if self.args.verbose and self.args.log_interval>0:\n",
    "                    if epoch % self.args.log_interval == 0:\n",
    "                        status_str = '\\tTrain Epoch: {} \\t Loss: {:.6f}'.format(epoch, loss)\n",
    "                        try:\n",
    "                            from tqdm import tqdm\n",
    "                            tqdm.write(status_str)\n",
    "                        except Exception as e:\n",
    "                            print(e)\n",
    "                            print(status_str)\n",
    "            self.model.eval()\n",
    "\n",
    "    def train_epoch(self, epoch, seed, rank=0):\n",
    "        torch.manual_seed(seed + epoch + rank*self.args.epochs)\n",
    "        for batch_idx, (data, target) in enumerate(self.dataset.train_loader):\n",
    "            data, target = data.to(self.device), target.to(self.device)\n",
    "            # Clear all accumulated gradients\n",
    "            self.optimizer.zero_grad()\n",
    "            # Predict classes using images from the train set\n",
    "            output = self.model(data)\n",
    "            # Compute the loss based on the predictions and actual labels\n",
    "            loss = F.nll_loss(output, target, reduction='sum')\n",
    "            # Backpropagate the loss\n",
    "            loss.backward()\n",
    "            # Adjust parameters according to the computed gradients\n",
    "            self.optimizer.step()\n",
    "        return loss.item()\n",
    "\n",
    "    def classify(self, image, t):\n",
    "        from PIL import Image\n",
    "        image = Image.fromarray(image)#.astype('uint8'), 'RGB')\n",
    "        data = t(image).unsqueeze(0)\n",
    "        # data.requires_grad = False\n",
    "        self.model.eval()\n",
    "        #output = self.model(data)\n",
    "        #return np.exp(output.data.numpy()[0, :].astype(np.float))\n",
    "        output = self.model(data.cuda())\n",
    "        return np.exp(output.cpu().data.numpy()[0, :].astype(np.float))\n",
    "\n",
    "    def test(self, dataloader=None):\n",
    "        if dataloader is None:\n",
    "            dataloader = self.dataset.test_loader\n",
    "        self.model.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        for data, target in dataloader:\n",
    "            data, target = data.to(self.device), target.to(self.device)\n",
    "            output = self.model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.data.view_as(pred)).long().cpu().sum()\n",
    "\n",
    "        test_loss /= len(dataloader.dataset)\n",
    "\n",
    "        if self.args.log_interval>0:\n",
    "            print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            test_loss, correct, len(dataloader.dataset),\n",
    "            100. * correct / len(dataloader.dataset)))\n",
    "        return correct.numpy() / len(dataloader.dataset)\n",
    "\n",
    "    def show(self, gamma=.5, noise_level=.4, transpose=True, only_wrong=False):\n",
    "        for idx, (data, target) in enumerate(self.dataset.test_loader):\n",
    "            #data, target = next(iter(self.dataset.test_loader))\n",
    "            data, target = data.to(self.device), target.to(self.device)\n",
    "            output = self.model(data)\n",
    "            pred = output.data.max(1, keepdim=False)[1] # get the index of the max log-probability\n",
    "            #if only_wrong and not pred == target :\n",
    "            if only_wrong and not all(pred) == all(target) :\n",
    "                #print(target, self.dataset.dataset.imgs[self.dataset.test_loader.dataset.indices[idx]])\n",
    "                print('target:' + ' '.join('%5s' % self.dataset.dataset.classes[j] for j in target))\n",
    "                print('pred  :' + ' '.join('%5s' % self.dataset.dataset.classes[j] for j in pred))\n",
    "                #print(target, pred)\n",
    "\n",
    "                from torchvision.utils import make_grid\n",
    "                npimg = make_grid(data, normalize=True).numpy()\n",
    "                import matplotlib.pyplot as plt\n",
    "                fig, ax = plt.subplots(figsize=((13, 5)))\n",
    "                import numpy as np\n",
    "                if transpose:\n",
    "                    ax.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "                else:\n",
    "                    ax.imshow(npimg)\n",
    "                plt.setp(ax, xticks=[], yticks=[])\n",
    "\n",
    "                return fig, ax\n",
    "            else:\n",
    "                return None, None\n",
    "\n",
    "\n",
    "    def main(self, path=None, seed=None):\n",
    "        self.train(path=path, seed=seed)\n",
    "        Accuracy = self.test()\n",
    "        return Accuracy\n",
    "\n",
    "\n",
    "import time\n",
    "class MetaML:\n",
    "    def __init__(self, args, base = 2, N_scan = 9, tag='', verbose=0, log_interval=0):\n",
    "        self.args = args\n",
    "        self.seed = args.seed\n",
    "\n",
    "        self.base = base\n",
    "        self.N_scan = N_scan\n",
    "        self.tag = tag\n",
    "        self.default = dict(verbose=verbose, log_interval=log_interval)\n",
    "\n",
    "    def test(self, args, seed):\n",
    "        # makes a loop for the cross-validation of results\n",
    "        Accuracy = []\n",
    "        for i_cv in range(self.args.N_cv):\n",
    "            ml = ML(args)\n",
    "            ml.train(seed=seed + i_cv)\n",
    "            Accuracy.append(ml.test())\n",
    "        return np.array(Accuracy)\n",
    "\n",
    "    def protocol(self, args, seed):\n",
    "        t0 = time.time()\n",
    "        Accuracy = self.test(args, seed)\n",
    "        t1 = time.time() - t0\n",
    "        Accuracy = np.hstack((Accuracy, [t1]))\n",
    "        return Accuracy\n",
    "\n",
    "    def scan(self, parameter, values):\n",
    "        import os\n",
    "        try:\n",
    "            os.mkdir('_tmp_scanning')\n",
    "        except:\n",
    "            pass\n",
    "        print('scanning over', parameter, '=', values)\n",
    "        seed = self.seed\n",
    "        Accuracy = {}\n",
    "        for value in values:\n",
    "            if isinstance(value, int):\n",
    "                value_str = str(value)\n",
    "            else:\n",
    "                value_str = '%.3f' % value\n",
    "            path = '_tmp_scanning/' + parameter + '_' + self.tag + '_' + value_str.replace('.', '_') + '.npy'\n",
    "            print ('For parameter', parameter, '=', value_str, ', ', end=\" \")\n",
    "            if not(os.path.isfile(path + '_lock')):\n",
    "                if not(os.path.isfile(path)):\n",
    "                    open(path + '_lock', 'w').close()\n",
    "                    try:\n",
    "                        args = easydict.EasyDict(self.args.copy())\n",
    "                        args[parameter] = value\n",
    "                        Accuracy[value] = self.protocol(args, seed)\n",
    "                        np.save(path, Accuracy[value])\n",
    "                        os.remove(path + '_lock')\n",
    "                    except Exception as e:\n",
    "                        print('Failed with error', e)\n",
    "                else:\n",
    "                    Accuracy[value] = np.load(path)\n",
    "\n",
    "                try:\n",
    "                    print('Accuracy={:.1f}% +/- {:.1f}%'.format(Accuracy[value][:-1].mean()*100, Accuracy[value][:-1].std()*100),\n",
    "                  ' in {:.1f} seconds'.format(Accuracy[value][-1]))\n",
    "                except Exception as e:\n",
    "                    print('Failed with error', e)\n",
    "\n",
    "            else:\n",
    "                print(' currently locked with ', path + '_lock')\n",
    "            seed += 1\n",
    "        return Accuracy\n",
    "\n",
    "    def parameter_scan(self, parameter, display=False):\n",
    "        if parameter in ['momentum', 'conv1_bn_momentum', 'conv2_bn_momentum', 'dense_bn_momentum']:\n",
    "            values = np.linspace(0, 1, self.N_scan, endpoint=True)\n",
    "        else:\n",
    "            values = self.args[parameter] * np.logspace(-1, 1, self.N_scan, base=self.base)\n",
    "        if isinstance(self.args[parameter], int):\n",
    "            # print('integer detected') # DEBUG\n",
    "            values =  [int(k) for k in values]\n",
    "        Accuracy = self.scan(parameter, values)\n",
    "        if display:\n",
    "            fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "        return Accuracy\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import os\n",
    "    filename = 'figures/accuracy.pdf'\n",
    "    if False : #not os.path.exists(filename) :\n",
    "        args = init(verbose=0, log_interval=0, epochs=20)\n",
    "        from gaze import MetaML\n",
    "        mml = MetaML(args)\n",
    "        Accuracy = mml.protocol(args, 42)\n",
    "        print('Accuracy', Accuracy[:-1].mean(), '+/-', Accuracy[:-1].std())\n",
    "        import numpy as np\n",
    "        import matplotlib.pyplot as plt\n",
    "        fig, ax = plt.subplots(figsize=((8, 5)))\n",
    "        n, bins, patches = ax.hist(Accuracy[:-1]*100, bins=np.linspace(0, 100, 100), alpha=.4)\n",
    "        ax.vlines(np.median(Accuracy[:-1])*100, 0, n.max(), 'g', linestyles='dashed', label='median')\n",
    "        ax.vlines(25, 0, n.max(), 'r', linestyles='dashed', label='chance level')\n",
    "        ax.vlines(100, 0, n.max(), 'k', label='max')\n",
    "        ax.set_xlabel('Accuracy (%)')\n",
    "        ax.set_ylabel('Smarts')\n",
    "        ax.legend(loc='best')\n",
    "        plt.show()\n",
    "        plt.savefig(filename)\n",
    "        plt.savefig(filename.replace('.pdf', '.png'))\n",
    "\n",
    "    print(50*'-')\n",
    "    print(' parameter scan')\n",
    "    print(50*'-')\n",
    "\n",
    "    if False :\n",
    "        print(50*'-')\n",
    "        print('Default parameters')\n",
    "        print(50*'-')\n",
    "        args = init(verbose=0, log_interval=0)\n",
    "        ml = ML(args)\n",
    "        ml.main()\n",
    "    if False :\n",
    "        args = init(verbose=0, log_interval=0)\n",
    "        mml = MetaML(args)\n",
    "        if torch.cuda.is_available():\n",
    "            mml.scan('no_cuda', [True, False])\n",
    "        else:\n",
    "            mml.scan('no_cuda', [True])\n",
    "\n",
    "    # for base in [2]:#, 8]:\n",
    "    for base in [2, 8]:\n",
    "        print(50*'-')\n",
    "        print(' base=', base)\n",
    "        print(50*'-')\n",
    "\n",
    "        print(50*'-')\n",
    "        print(' parameter scan : data')\n",
    "        print(50*'-')\n",
    "        args = init(verbose=0, log_interval=0)\n",
    "        mml = MetaML(args, base=base)\n",
    "        for parameter in ['size', 'fullsize', 'crop', 'mean', 'std']:\n",
    "            mml.parameter_scan(parameter)\n",
    "\n",
    "        print(50*'-')\n",
    "        args = init(verbose=0, log_interval=0)\n",
    "        mml = MetaML(args)\n",
    "        print(' parameter scan : network')\n",
    "        print(50*'-')\n",
    "        for parameter in ['conv1_kernel_size',\n",
    "                          'conv1_dim',\n",
    "                          'conv1_bn_momentum',\n",
    "                          'conv2_kernel_size',\n",
    "                          'conv2_dim',\n",
    "                          'conv2_bn_momentum',\n",
    "                          'stride1', 'stride2',\n",
    "                          'dense_bn_momentum',\n",
    "                          'dimension']:\n",
    "            mml.parameter_scan(parameter)\n",
    "\n",
    "        args = init(verbose=0, log_interval=0)\n",
    "        mml = MetaML(args, base=base)\n",
    "        print(' parameter scan : learning ')\n",
    "        print(50*'-')\n",
    "        print('Using SGD')\n",
    "        print(50*'-')\n",
    "        for parameter in ['lr', 'momentum', 'batch_size', 'epochs']:\n",
    "            mml.parameter_scan(parameter)\n",
    "        print(50*'-')\n",
    "        print('Using ADAM')\n",
    "        print(50*'-')\n",
    "        args = init(verbose=0, log_interval=0, do_adam=True)\n",
    "        mml = MetaML(args, tag='adam')\n",
    "        for parameter in ['lr', 'momentum', 'batch_size', 'epochs']:\n",
    "            mml.parameter_scan(parameter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
