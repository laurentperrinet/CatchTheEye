{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T09:37:03.301677Z",
     "start_time": "2018-10-03T09:37:03.274704Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T09:37:04.263739Z",
     "start_time": "2018-10-03T09:37:03.578092Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import time\n",
    "time.sleep(8*3600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## detecting and cropping faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1114 sample images;  892  to train 222 to test\n"
     ]
    }
   ],
   "source": [
    "done = False\n",
    "done = True\n",
    "\n",
    "from gaze import init, Data\n",
    "args = init(batch_size=8, no_cuda=True, verbose=1)\n",
    "d = Data(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/blink/2018-09-05_Laurent_090.png\n",
      "dataset/blink/2018-09-12_Laurent_035.png\n",
      "dataset/blink/2018-09-12_Laurent_223.png\n",
      "dataset/blink/2018-09-12_Laurent_237.png\n",
      "dataset/blink/2018-09-12_Laurent_222.png\n",
      "dataset/blink/2018-09-14_Laurent_121.png\n",
      "dataset/blink/2018-09-04_Laurent_180.png\n",
      "dataset/blink/2018-09-12_Laurent_020.png\n",
      "dataset/blink/2018-09-05_Laurent_085.png\n",
      "dataset/blink/2018-09-14_Laurent_069.png\n",
      "dataset/center/2018-09-05_Laurent_244.png\n",
      "dataset/center/2018-09-05_Laurent_091.png\n",
      "dataset/center/2018-09-04_Laurent_16.png\n",
      "dataset/center/2018-09-12_Laurent_140.png\n",
      "dataset/center/2018-09-14_Laurent_243.png\n",
      "dataset/center/2018-09-12_Laurent_168.png\n",
      "dataset/center/2018-09-12_Laurent_183.png\n",
      "dataset/center/2018-09-04_Laurent_221.png\n",
      "dataset/center/2018-09-04_Laurent_235.png\n",
      "dataset/center/2018-09-14_Laurent_096.png\n",
      "dataset/left/2018-09-14_Laurent_108.png\n",
      "dataset/left/2018-09-12_Laurent_236.png\n",
      "dataset/left/2018-09-05_Laurent_091.png\n",
      "dataset/left/2018-09-12_Laurent_008.png\n",
      "dataset/left/2018-09-05_Laurent_052.png\n",
      "dataset/left/2018-09-12_Laurent_154.png\n",
      "dataset/left/2018-09-04_Laurent_209.png\n",
      "dataset/left/2018-09-05_Laurent_126.png\n",
      "dataset/left/2018-09-05_Laurent_132.png\n",
      "dataset/left/2018-09-14_Laurent_041.png\n",
      "dataset/right/2018-09-04_Laurent_195.png\n",
      "dataset/right/2018-09-05_Laurent_250.png\n",
      "dataset/right/2018-09-04_Laurent_143.png\n",
      "dataset/right/2018-09-12_Laurent_034.png\n",
      "dataset/right/2018-09-05_Laurent_046.png\n",
      "dataset/right/2018-09-12_Laurent_197.png\n",
      "dataset/right/2018-09-05_Laurent_126.png\n",
      "dataset/right/2018-09-05_Laurent_132.png\n",
      "dataset/right/2018-09-14_Laurent_055.png\n",
      "dataset/right/2018-09-14_Laurent_082.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "datapath_faces = 'dataset_faces'\n",
    "datapath = 'dataset'\n",
    "\n",
    "if True:\n",
    "    n_show = 10\n",
    "    for target in d.classes:\n",
    "        for filename in glob.glob(os.path.join(datapath, target) + '/*.png')[-n_show:]:\n",
    "            print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "if not done:\n",
    "    import time\n",
    "    from gaze import FaceExtractor\n",
    "    f = FaceExtractor()\n",
    "    timings = []\n",
    "    for target in d.classes:\n",
    "        for filename in glob.glob(os.path.join(datapath, target) + '/*.png'):\n",
    "            frame = imageio.imread(filename)\n",
    "            t0 = time.time()\n",
    "            face = f.face_extractor(frame)\n",
    "            t1 = time.time()\n",
    "            timings.append(t1-t0)\n",
    "            if False:\n",
    "                print(\"Number of faces detected: {}\".format(len(dets)))\n",
    "                for i, d in enumerate(dets):\n",
    "                    print(\"Detection {}: Left: {} Top: {} Right: {} Bottom: {}\".format(\n",
    "                        i, d.left(), d.top(), d.right(), d.bottom()))\n",
    "\n",
    "            if False:\n",
    "                # Create figure and axes\n",
    "                fig, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "                # Display the image\n",
    "                ax.imshow(frame)\n",
    "\n",
    "                # Create a Rectangle patch\n",
    "                rect = patches.Rectangle((d.bottom(), d.left()), d.right()-d.left(), d.top()-d.bottom(), linewidth=1, edgecolor='r', facecolor='none')\n",
    "\n",
    "                # Add the patch to the Axes\n",
    "                ax.add_patch(rect)\n",
    "                plt.show()    \n",
    "            if False:\n",
    "                # Create figure and axes\n",
    "                fig, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "                # Display the cropped image\n",
    "                ax.imshow(face)\n",
    "\n",
    "                plt.show()                \n",
    "\n",
    "            filename_face = filename.replace(datapath, datapath_faces)\n",
    "            imageio.imwrite(filename_face, face) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not done:\n",
    "    timings = np.array(timings) * 1000\n",
    "    print('timings in ms =', timings.mean(), '+/-', timings.std()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not done:\n",
    "    fig, ax = plt.subplots(figsize=((8, 5)))\n",
    "    n, bins, patches = ax.hist(timings, bins=np.linspace(100, 200, 100), alpha=.4)\n",
    "    ax.vlines(np.median(timings), 0, n.max(), 'g', linestyles='dashed', label='median = %.3f ms' % np.median(timings))\n",
    "    #ax.vlines(25, 0, n.max(), 'r', linestyles='dashed', label='chance level')\n",
    "    #ax.vlines(100, 0, n.max(), 'k', label='max')\n",
    "    ax.set_xlabel('Timings (ms)')\n",
    "    ax.set_ylabel('Smarts')\n",
    "    ax.legend(loc='best')\n",
    "    if False:\n",
    "        plt.show() \n",
    "    else:\n",
    "        plt.savefig('dlib_timings.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training the model on the cropped faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T09:37:54.127982Z",
     "start_time": "2018-10-03T09:37:53.674230Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters= {'dataset_folder': 'dataset', 'dataset_faces_folder': 'dataset_faces', 'batch_size': 8, 'test_batch_size': 1, 'size_test_set': 0.2, 'epochs': 20, 'do_adam': False, 'lr': 0.025, 'momentum': 0.05, 'no_cuda': False, 'num_processes': 1, 'seed': 42, 'log_interval': 1, 'fullsize': 64, 'crop': 64, 'size': 64, 'mean': 0.36, 'std': 0.3, 'conv1_dim': 9, 'conv1_kernel_size': 18, 'conv2_dim': 36, 'conv2_kernel_size': 14, 'stride1': 2, 'stride2': 4, 'N_cv': 20, 'dimension': 30, 'verbose': 1}\n"
     ]
    }
   ],
   "source": [
    "from gaze import init\n",
    "#epochs = 40\n",
    "#args = init(verbose=0, epochs=epochs)\n",
    "args = init(verbose=1)\n",
    "print('Parameters=', args)\n",
    "\n",
    "path = '_Regard.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T09:37:55.355101Z",
     "start_time": "2018-10-03T09:37:55.167350Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--  1 laurentperrinet  staff  308360 Oct  3 11:31 _Regard.pt\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l {path}\n",
    "#!rm {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T09:37:58.352749Z",
     "start_time": "2018-10-03T09:37:58.281559Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda? False\n",
      "Found 1114 sample images;  892  to train 222 to test\n",
      "Loading file _Regard.pt\n"
     ]
    }
   ],
   "source": [
    "from gaze import ML\n",
    "ml = ML(args)\n",
    "ml.train(path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T09:38:00.648661Z",
     "start_time": "2018-10-03T09:38:00.613854Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method train in module torch.nn.modules.module:\n",
      "\n",
      "train(mode=True) method of gaze.Net instance\n",
      "    Sets the module in training mode.\n",
      "    \n",
      "    This has any effect only on certain modules. See documentations of\n",
      "    particular modules for details of their behaviors in training/evaluation\n",
      "    mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      "    etc.\n",
      "    \n",
      "    Returns:\n",
      "        Module: self\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ml.model.train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T09:38:04.697690Z",
     "start_time": "2018-10-03T09:38:02.591709Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.2230, Accuracy: 213/222 (95%)\n",
      "\n",
      "Accuracy=95.9%\n"
     ]
    }
   ],
   "source": [
    "Accuracy = ml.test()\n",
    "print('Accuracy={:.1f}%'.format(Accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing the one which are wrong:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for data, labels in ml.dataset.test_loader:\n",
    "    fig, ax = ml.show(only_wrong=True)\n",
    "    plt.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nteract": {
   "version": "0.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
