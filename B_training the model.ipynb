{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-05T17:18:53.715144Z",
     "start_time": "2018-10-05T17:18:53.678031Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-05T17:18:53.946976Z",
     "start_time": "2018-10-05T17:18:53.910904Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import time\n",
    "time.sleep(8*3600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## detecting and cropping faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-05T17:18:54.779056Z",
     "start_time": "2018-10-05T17:18:54.745625Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1358 sample images;  1087  to train 271 to test\n"
     ]
    }
   ],
   "source": [
    "done = False\n",
    "done = True\n",
    "\n",
    "from gaze import init, Data\n",
    "args = init(batch_size=8, no_cuda=True, verbose=1)\n",
    "d = Data(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-05T17:18:56.408389Z",
     "start_time": "2018-10-05T17:18:56.366477Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/blink/2018-09-12_Laurent_035.png\n",
      "dataset/blink/2018-09-12_Laurent_223.png\n",
      "dataset/blink/2018-09-12_Laurent_237.png\n",
      "dataset/blink/2018-09-12_Laurent_222.png\n",
      "dataset/blink/2018-09-14_Laurent_121.png\n",
      "dataset/blink/2018-09-04_Laurent_180.png\n",
      "dataset/blink/2018-10-03_Laurent_116.png\n",
      "dataset/blink/2018-09-12_Laurent_020.png\n",
      "dataset/blink/2018-09-05_Laurent_085.png\n",
      "dataset/blink/2018-09-14_Laurent_069.png\n",
      "dataset/center/2018-09-05_Laurent_091.png\n",
      "dataset/center/2018-09-04_Laurent_16.png\n",
      "dataset/center/2018-09-12_Laurent_140.png\n",
      "dataset/center/2018-09-14_Laurent_243.png\n",
      "dataset/center/2018-09-12_Laurent_168.png\n",
      "dataset/center/2018-09-12_Laurent_183.png\n",
      "dataset/center/2018-09-04_Laurent_221.png\n",
      "dataset/center/2018-09-04_Laurent_235.png\n",
      "dataset/center/2018-10-03_Laurent_089.png\n",
      "dataset/center/2018-10-03_Laurent_076.png\n",
      "dataset/left/2018-09-12_Laurent_236.png\n",
      "dataset/left/2018-09-05_Laurent_091.png\n",
      "dataset/left/2018-09-12_Laurent_008.png\n",
      "dataset/left/2018-09-05_Laurent_052.png\n",
      "dataset/left/2018-09-12_Laurent_154.png\n",
      "dataset/left/2018-09-04_Laurent_209.png\n",
      "dataset/left/2018-09-05_Laurent_126.png\n",
      "dataset/left/2018-09-05_Laurent_132.png\n",
      "dataset/left/2018-09-14_Laurent_041.png\n",
      "dataset/left/2018-10-03_Laurent_062.png\n",
      "dataset/right/2018-10-03_Laurent_102.png\n",
      "dataset/right/2018-09-05_Laurent_250.png\n",
      "dataset/right/2018-09-04_Laurent_143.png\n",
      "dataset/right/2018-09-12_Laurent_034.png\n",
      "dataset/right/2018-09-05_Laurent_046.png\n",
      "dataset/right/2018-09-12_Laurent_197.png\n",
      "dataset/right/2018-09-05_Laurent_126.png\n",
      "dataset/right/2018-09-05_Laurent_132.png\n",
      "dataset/right/2018-09-14_Laurent_055.png\n",
      "dataset/right/2018-09-14_Laurent_082.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "datapath_faces = 'dataset_faces'\n",
    "datapath = 'dataset'\n",
    "\n",
    "if True:\n",
    "    n_show = 10\n",
    "    for target in d.classes:\n",
    "        for filename in glob.glob(os.path.join(datapath, target) + '/*.png')[-n_show:]:\n",
    "            print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-05T17:18:57.322834Z",
     "start_time": "2018-10-05T17:18:57.292958Z"
    }
   },
   "outputs": [],
   "source": [
    "import imageio\n",
    "if not done:\n",
    "    import time\n",
    "    from gaze import FaceExtractor\n",
    "    FE = FaceExtractor()\n",
    "    timings = []\n",
    "    for target in d.classes:\n",
    "        for filename in glob.glob(os.path.join(datapath, target) + '/*.png'):\n",
    "            frame = imageio.imread(filename)\n",
    "            t0 = time.time()\n",
    "            face = FE.face_extractor(frame)\n",
    "            t1 = time.time()\n",
    "            timings.append(t1-t0)\n",
    "            if False:\n",
    "                print(\"Number of faces detected: {}\".format(len(dets)))\n",
    "                for i, d in enumerate(dets):\n",
    "                    print(\"Detection {}: Left: {} Top: {} Right: {} Bottom: {}\".format(\n",
    "                        i, d.left(), d.top(), d.right(), d.bottom()))\n",
    "\n",
    "            if False:\n",
    "                # Create figure and axes\n",
    "                fig, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "                # Display the image\n",
    "                ax.imshow(frame)\n",
    "\n",
    "                # Create a Rectangle patch\n",
    "                rect = patches.Rectangle((d.bottom(), d.left()), d.right()-d.left(), d.top()-d.bottom(), linewidth=1, edgecolor='r', facecolor='none')\n",
    "\n",
    "                # Add the patch to the Axes\n",
    "                ax.add_patch(rect)\n",
    "                plt.show()    \n",
    "            if False:\n",
    "                # Create figure and axes\n",
    "                fig, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "                # Display the cropped image\n",
    "                ax.imshow(face)\n",
    "\n",
    "                plt.show()                \n",
    "\n",
    "            filename_face = filename.replace(datapath, datapath_faces)\n",
    "            imageio.imwrite(filename_face, face) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-05T17:18:58.497855Z",
     "start_time": "2018-10-05T17:18:58.477379Z"
    }
   },
   "outputs": [],
   "source": [
    "if not done:\n",
    "    timings = np.array(timings) * 1000\n",
    "    print('timings in ms =', timings.mean(), '+/-', timings.std()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-05T17:18:58.725994Z",
     "start_time": "2018-10-05T17:18:58.694675Z"
    }
   },
   "outputs": [],
   "source": [
    "if not done:\n",
    "    fig, ax = plt.subplots(figsize=((8, 5)))\n",
    "    n, bins, patches = ax.hist(timings, bins=np.linspace(100, 200, 100), alpha=.4)\n",
    "    ax.vlines(np.median(timings), 0, n.max(), 'g', linestyles='dashed', label='median = %.3f ms' % np.median(timings))\n",
    "    #ax.vlines(25, 0, n.max(), 'r', linestyles='dashed', label='chance level')\n",
    "    #ax.vlines(100, 0, n.max(), 'k', label='max')\n",
    "    ax.set_xlabel('Timings (ms)')\n",
    "    ax.set_ylabel('Smarts')\n",
    "    ax.legend(loc='best')\n",
    "    if False:\n",
    "        plt.show() \n",
    "    else:\n",
    "        plt.savefig('dlib_timings.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training the model on the cropped faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-05T17:27:44.698880Z",
     "start_time": "2018-10-05T17:27:44.664957Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters= {'dataset_folder': 'dataset', 'dataset_faces_folder': 'dataset_faces', 'batch_size': 8, 'test_batch_size': 1, 'size_test_set': 0.2, 'epochs': 20, 'do_adam': False, 'lr': 0.025, 'momentum': 0.05, 'no_cuda': False, 'num_processes': 1, 'seed': 42, 'log_interval': 0, 'fullsize': 75, 'crop': 64, 'size': 64, 'mean': 0.6, 'std': 0.3, 'conv1_dim': 9, 'conv1_kernel_size': 18, 'conv2_dim': 36, 'conv2_kernel_size': 14, 'conv1_pdropout': 0.1, 'conv2_pdropout': 0.1, 'stride1': 2, 'stride2': 4, 'N_cv': 20, 'dimension': 30, 'verbose': 1}\n"
     ]
    }
   ],
   "source": [
    "from gaze import init\n",
    "#epochs = 400\n",
    "#args = init(verbose=0, epochs=epochs)\n",
    "args = init(verbose=1)\n",
    "print('Parameters=', args)\n",
    "\n",
    "path = '_Regard.pt'\n",
    "path = '_Regard_dropout.pt'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-05T17:19:12.657164Z",
     "start_time": "2018-10-05T17:19:12.635455Z"
    }
   },
   "source": [
    "from gaze import init\n",
    "epochs = 400\n",
    "args = init(verbose=0, epochs=epochs)\n",
    "path = '_Regard_400.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-05T17:27:46.603239Z",
     "start_time": "2018-10-05T17:27:46.324058Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--  1 laurentperrinet  staff  308385 Oct  5 19:26 _Regard_dropout.pt\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l {path}\n",
    "\n",
    "!rm {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-05T17:33:53.897853Z",
     "start_time": "2018-10-05T17:27:47.541212Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Train Epoch:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1358 sample images;  1087  to train 271 to test\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch: 100%|██████████| 20/20 [06:06<00:00,  8.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at _Regard_dropout.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from gaze import ML\n",
    "ml = ML(args)\n",
    "ml.train(path=path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-05T17:33:55.918090Z",
     "start_time": "2018-10-05T17:33:53.901457Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=95.6%\n"
     ]
    }
   ],
   "source": [
    "Accuracy = ml.test()\n",
    "print('Accuracy={:.1f}%'.format(Accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing the one which are wrong:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-05T16:46:13.788886Z",
     "start_time": "2018-10-05T16:46:13.755150Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1348)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(ml.dataset.test_loader.dataset.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-05T16:46:16.244561Z",
     "start_time": "2018-10-05T16:46:16.220759Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('dataset_faces/blink/2018-09-04_Laurent_100.png', 0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml.dataset.dataset.imgs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-05T16:46:33.031238Z",
     "start_time": "2018-10-05T16:46:33.000657Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dataset_faces/blink/2018-09-04_Laurent_100.png'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml.dataset.dataset.imgs[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-05T16:46:18.172602Z",
     "start_time": "2018-10-05T16:46:17.047617Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1]) ('dataset_faces/center/2018-09-04_Laurent_99.png', 1)\n",
      "tensor([1]) ('dataset_faces/center/2018-09-05_Laurent_014.png', 1)\n",
      "tensor([1]) ('dataset_faces/center/2018-09-05_Laurent_007.png', 1)\n",
      "tensor([0]) ('dataset_faces/blink/2018-09-04_Laurent_172.png', 0)\n",
      "tensor([2]) ('dataset_faces/left/2018-09-05_Laurent_223.png', 2)\n",
      "tensor([3]) ('dataset_faces/right/2018-10-03_Laurent_207.png', 3)\n",
      "tensor([0]) ('dataset_faces/blink/2018-09-05_Laurent_160.png', 0)\n",
      "tensor([1]) ('dataset_faces/center/2018-09-04_Laurent_208.png', 1)\n",
      "tensor([1]) ('dataset_faces/center/2018-09-12_Laurent_109.png', 1)\n",
      "tensor([1]) ('dataset_faces/center/2018-09-05_Laurent_138.png', 1)\n",
      "tensor([0]) ('dataset_faces/blink/2018-09-05_Laurent_173.png', 0)\n",
      "tensor([2]) ('dataset_faces/left/2018-10-03_Laurent_056.png', 2)\n",
      "tensor([1]) ('dataset_faces/center/2018-09-12_Laurent_171.png', 1)\n",
      "tensor([2]) ('dataset_faces/left/2018-09-12_Laurent_058.png', 2)\n",
      "tensor([3]) ('dataset_faces/right/2018-09-05_Laurent_128.png', 3)\n",
      "tensor([3]) ('dataset_faces/right/2018-09-05_Laurent_032.png', 3)\n",
      "tensor([3]) ('dataset_faces/right/2018-09-05_Laurent_145.png', 3)\n",
      "tensor([2]) ('dataset_faces/left/2018-09-04_Laurent_119.png', 2)\n",
      "tensor([3]) ('dataset_faces/right/2018-10-03_Laurent_209.png', 3)\n",
      "tensor([1]) ('dataset_faces/center/2018-09-12_Laurent_052.png', 1)\n",
      "tensor([0]) ('dataset_faces/blink/2018-09-14_Laurent_232.png', 0)\n",
      "tensor([0]) ('dataset_faces/blink/2018-09-04_Laurent_2.png', 0)\n",
      "tensor([1]) ('dataset_faces/center/2018-09-14_Laurent_176.png', 1)\n",
      "tensor([1]) ('dataset_faces/center/2018-09-05_Laurent_002.png', 1)\n",
      "tensor([3]) ('dataset_faces/right/2018-09-05_Laurent_028.png', 3)\n",
      "tensor([3]) ('dataset_faces/right/2018-10-03_Laurent_173.png', 3)\n",
      "tensor([3]) ('dataset_faces/right/2018-09-14_Laurent_216.png', 3)\n",
      "tensor([0]) ('dataset_faces/blink/2018-09-12_Laurent_162.png', 0)\n",
      "tensor([0]) ('dataset_faces/blink/2018-09-14_Laurent_242.png', 0)\n",
      "tensor([3]) ('dataset_faces/right/2018-09-04_Laurent_14.png', 3)\n",
      "tensor([3]) ('dataset_faces/right/2018-09-04_Laurent_126.png', 3)\n",
      "tensor([3]) ('dataset_faces/right/2018-10-03_Laurent_085.png', 3)\n",
      "tensor([2]) ('dataset_faces/left/2018-09-14_Laurent_032.png', 2)\n",
      "tensor([1]) ('dataset_faces/center/2018-09-12_Laurent_106.png', 1)\n",
      "tensor([1]) ('dataset_faces/center/2018-09-05_Laurent_070.png', 1)\n",
      "tensor([2]) ('dataset_faces/left/2018-09-05_Laurent_028.png', 2)\n",
      "tensor([3]) ('dataset_faces/right/2018-09-04_Laurent_154.png', 3)\n",
      "tensor([3]) ('dataset_faces/right/2018-09-12_Laurent_195.png', 3)\n",
      "tensor([2]) ('dataset_faces/left/2018-09-05_Laurent_115.png', 2)\n",
      "tensor([1]) ('dataset_faces/center/2018-09-14_Laurent_205.png', 1)\n",
      "tensor([3]) ('dataset_faces/right/2018-09-14_Laurent_239.png', 3)\n",
      "tensor([3]) ('dataset_faces/right/2018-09-14_Laurent_146.png', 3)\n",
      "tensor([1]) ('dataset_faces/center/2018-09-12_Laurent_238.png', 1)\n",
      "tensor([1]) ('dataset_faces/center/2018-10-03_Laurent_200.png', 1)\n",
      "tensor([3]) ('dataset_faces/right/2018-09-04_Laurent_233.png', 3)\n",
      "tensor([3]) ('dataset_faces/right/2018-09-14_Laurent_238.png', 3)\n",
      "tensor([3]) ('dataset_faces/right/2018-10-03_Laurent_133.png', 3)\n",
      "tensor([2]) ('dataset_faces/left/2018-09-12_Laurent_116.png', 2)\n",
      "tensor([0]) ('dataset_faces/blink/2018-09-05_Laurent_219.png', 0)\n",
      "tensor([1]) ('dataset_faces/center/2018-09-12_Laurent_160.png', 1)\n",
      "tensor([3]) ('dataset_faces/right/2018-09-04_Laurent_131.png', 3)\n",
      "tensor([0]) ('dataset_faces/blink/2018-09-12_Laurent_025.png', 0)\n",
      "tensor([0]) ('dataset_faces/blink/2018-09-04_Laurent_55.png', 0)\n",
      "tensor([1]) ('dataset_faces/center/2018-09-05_Laurent_195.png', 1)\n",
      "tensor([1]) ('dataset_faces/center/2018-09-14_Laurent_068.png', 1)\n",
      "tensor([1]) ('dataset_faces/center/2018-09-04_Laurent_145.png', 1)\n",
      "tensor([0]) ('dataset_faces/blink/2018-09-04_Laurent_20.png', 0)\n",
      "tensor([0]) ('dataset_faces/blink/2018-09-14_Laurent_075.png', 0)\n",
      "tensor([1]) ('dataset_faces/center/2018-10-03_Laurent_022.png', 1)\n",
      "tensor([0]) ('dataset_faces/blink/2018-10-03_Laurent_099.png', 0)\n",
      "tensor([3]) ('dataset_faces/right/2018-09-04_Laurent_195.png', 3)\n",
      "tensor([1]) ('dataset_faces/center/2018-09-05_Laurent_074.png', 1)\n",
      "tensor([0]) ('dataset_faces/blink/2018-09-14_Laurent_006.png', 0)\n",
      "tensor([1]) ('dataset_faces/center/2018-10-03_Laurent_028.png', 1)\n",
      "tensor([1]) ('dataset_faces/center/2018-09-05_Laurent_075.png', 1)\n",
      "tensor([2]) ('dataset_faces/left/2018-09-05_Laurent_140.png', 2)\n",
      "tensor([1]) ('dataset_faces/center/2018-09-14_Laurent_000.png', 1)\n",
      "tensor([0]) ('dataset_faces/blink/2018-10-03_Laurent_145.png', 0)\n",
      "tensor([3]) ('dataset_faces/right/2018-09-14_Laurent_024.png', 3)\n",
      "tensor([3]) ('dataset_faces/right/2018-09-05_Laurent_149.png', 3)\n",
      "tensor([3]) ('dataset_faces/right/2018-09-14_Laurent_161.png', 3)\n",
      "tensor([1]) ('dataset_faces/center/2018-09-14_Laurent_213.png', 1)\n",
      "tensor([2]) ('dataset_faces/left/2018-09-04_Laurent_253.png', 2)\n",
      "tensor([0]) ('dataset_faces/blink/2018-09-14_Laurent_254.png', 0)\n",
      "tensor([1]) ('dataset_faces/center/2018-09-05_Laurent_167.png', 1)\n",
      "tensor([0]) ('dataset_faces/blink/2018-10-03_Laurent_070.png', 0)\n",
      "tensor([3]) ('dataset_faces/right/2018-09-04_Laurent_69.png', 3)\n",
      "tensor([2]) ('dataset_faces/left/2018-09-12_Laurent_005.png', 2)\n",
      "tensor([0]) ('dataset_faces/blink/2018-09-14_Laurent_031.png', 0)\n",
      "tensor([3]) ('dataset_faces/right/2018-09-05_Laurent_183.png', 3)\n",
      "tensor([1]) ('dataset_faces/center/2018-09-05_Laurent_206.png', 1)\n",
      "tensor([2]) ('dataset_faces/left/2018-09-04_Laurent_114.png', 2)\n",
      "tensor([2]) ('dataset_faces/left/2018-09-04_Laurent_148.png', 2)\n",
      "tensor([3]) ('dataset_faces/right/2018-10-03_Laurent_048.png', 3)\n",
      "tensor([0]) ('dataset_faces/blink/2018-09-05_Laurent_129.png', 0)\n",
      "tensor([1]) ('dataset_faces/center/2018-09-14_Laurent_151.png', 1)\n",
      "tensor([3]) ('dataset_faces/right/2018-10-03_Laurent_042.png', 3)\n",
      "tensor([0]) ('dataset_faces/blink/2018-09-05_Laurent_205.png', 0)\n",
      "tensor([3]) ('dataset_faces/right/2018-09-04_Laurent_62.png', 3)\n",
      "tensor([3]) ('dataset_faces/right/2018-09-04_Laurent_135.png', 3)\n",
      "tensor([3]) ('dataset_faces/right/2018-09-05_Laurent_179.png', 3)\n",
      "tensor([0]) ('dataset_faces/blink/2018-09-05_Laurent_232.png', 0)\n",
      "tensor([0]) ('dataset_faces/blink/2018-09-05_Laurent_125.png', 0)\n",
      "tensor([3]) ('dataset_faces/right/2018-09-04_Laurent_37.png', 3)\n",
      "tensor([2]) ('dataset_faces/left/2018-09-12_Laurent_040.png', 2)\n",
      "tensor([2]) ('dataset_faces/left/2018-10-03_Laurent_061.png', 2)\n",
      "tensor([2]) ('dataset_faces/left/2018-09-12_Laurent_188.png', 2)\n",
      "tensor([0]) ('dataset_faces/blink/2018-09-14_Laurent_043.png', 0)\n",
      "tensor([3]) ('dataset_faces/right/2018-09-12_Laurent_192.png', 3)\n",
      "tensor([1]) ('dataset_faces/center/2018-09-12_Laurent_251.png', 1)\n",
      "tensor([0]) ('dataset_faces/blink/2018-10-03_Laurent_154.png', 0)\n",
      "tensor([1]) ('dataset_faces/center/2018-09-12_Laurent_245.png', 1)\n",
      "tensor([3]) ('dataset_faces/right/2018-09-14_Laurent_010.png', 3)\n",
      "tensor([0]) ('dataset_faces/blink/2018-09-05_Laurent_174.png', 0)\n",
      "tensor([3]) ('dataset_faces/right/2018-09-05_Laurent_021.png', 3)\n",
      "tensor([2]) ('dataset_faces/left/2018-10-03_Laurent_065.png', 2)\n",
      "tensor([1]) ('dataset_faces/center/2018-09-04_Laurent_59.png', 1)\n",
      "tensor([3]) ('dataset_faces/right/2018-09-04_Laurent_241.png', 3)\n",
      "tensor([1]) ('dataset_faces/center/2018-09-04_Laurent_70.png', 1)\n",
      "tensor([1]) ('dataset_faces/center/2018-09-05_Laurent_006.png', 1)\n",
      "tensor([1]) ('dataset_faces/center/2018-09-14_Laurent_009.png', 1)\n",
      "tensor([0]) ('dataset_faces/blink/2018-09-14_Laurent_163.png', 0)\n",
      "tensor([2]) ('dataset_faces/left/2018-09-12_Laurent_227.png', 2)\n",
      "tensor([2]) ('dataset_faces/left/2018-09-14_Laurent_078.png', 2)\n",
      "tensor([0]) ('dataset_faces/blink/2018-09-14_Laurent_057.png', 0)\n",
      "tensor([3]) ('dataset_faces/right/2018-09-05_Laurent_108.png', 3)\n",
      "tensor([0]) ('dataset_faces/blink/2018-09-12_Laurent_234.png', 0)\n",
      "tensor([1]) ('dataset_faces/center/2018-09-05_Laurent_079.png', 1)\n",
      "tensor([3]) ('dataset_faces/right/2018-09-12_Laurent_029.png', 3)\n",
      "tensor([2]) ('dataset_faces/left/2018-09-12_Laurent_154.png', 2)\n",
      "tensor([1]) ('dataset_faces/center/2018-10-03_Laurent_005.png', 1)\n",
      "tensor([2]) ('dataset_faces/left/2018-10-03_Laurent_172.png', 2)\n",
      "tensor([0]) ('dataset_faces/blink/2018-09-12_Laurent_178.png', 0)\n",
      "tensor([1]) ('dataset_faces/center/2018-09-05_Laurent_012.png', 1)\n",
      "tensor([1]) ('dataset_faces/center/2018-09-12_Laurent_186.png', 1)\n",
      "tensor([1]) ('dataset_faces/center/2018-09-05_Laurent_073.png', 1)\n",
      "tensor([3]) ('dataset_faces/right/2018-09-14_Laurent_026.png', 3)\n",
      "tensor([2]) ('dataset_faces/left/2018-09-04_Laurent_40.png', 2)\n",
      "tensor([0]) ('dataset_faces/blink/2018-10-03_Laurent_176.png', 0)\n",
      "tensor([3]) ('dataset_faces/right/2018-09-05_Laurent_182.png', 3)\n",
      "tensor([2]) ('dataset_faces/left/2018-09-05_Laurent_198.png', 2)\n",
      "tensor([0]) ('dataset_faces/blink/2018-09-04_Laurent_22.png', 0)\n",
      "tensor([2]) ('dataset_faces/left/2018-09-12_Laurent_144.png', 2)\n",
      "tensor([3]) ('dataset_faces/right/2018-10-03_Laurent_180.png', 3)\n",
      "tensor([2]) ('dataset_faces/left/2018-09-12_Laurent_142.png', 2)\n",
      "tensor([0]) ('dataset_faces/blink/2018-09-12_Laurent_041.png', 0)\n",
      "tensor([1]) ('dataset_faces/center/2018-09-05_Laurent_231.png', 1)\n",
      "tensor([2]) ('dataset_faces/left/2018-10-03_Laurent_231.png', 2)\n",
      "tensor([2]) ('dataset_faces/left/2018-09-12_Laurent_108.png', 2)\n",
      "tensor([1]) ('dataset_faces/center/2018-09-14_Laurent_198.png', 1)\n",
      "tensor([1]) ('dataset_faces/center/2018-09-12_Laurent_004.png', 1)\n",
      "tensor([0]) ('dataset_faces/blink/2018-10-03_Laurent_194.png', 0)\n",
      "tensor([0]) ('dataset_faces/blink/2018-09-14_Laurent_091.png', 0)\n",
      "tensor([3]) ('dataset_faces/right/2018-09-14_Laurent_185.png', 3)\n",
      "tensor([3]) ('dataset_faces/right/2018-09-04_Laurent_24.png', 3)\n",
      "tensor([3]) ('dataset_faces/right/2018-09-05_Laurent_006.png', 3)\n",
      "tensor([2]) ('dataset_faces/left/2018-09-04_Laurent_34.png', 2)\n",
      "tensor([3]) ('dataset_faces/right/2018-09-05_Laurent_169.png', 3)\n",
      "tensor([0]) ('dataset_faces/blink/2018-09-04_Laurent_93.png', 0)\n",
      "tensor([2]) ('dataset_faces/left/2018-09-04_Laurent_158.png', 2)\n",
      "tensor([3]) ('dataset_faces/right/2018-10-03_Laurent_004.png', 3)\n",
      "tensor([2]) ('dataset_faces/left/2018-09-05_Laurent_083.png', 2)\n",
      "tensor([0]) ('dataset_faces/blink/2018-09-12_Laurent_132.png', 0)\n",
      "tensor([0]) ('dataset_faces/blink/2018-09-04_Laurent_44.png', 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2]) ('dataset_faces/left/2018-09-04_Laurent_19.png', 2)\n",
      "tensor([2]) ('dataset_faces/left/2018-09-14_Laurent_065.png', 2)\n",
      "tensor([1]) ('dataset_faces/center/2018-09-12_Laurent_003.png', 1)\n",
      "tensor([1]) ('dataset_faces/center/2018-09-05_Laurent_084.png', 1)\n",
      "tensor([2]) ('dataset_faces/left/2018-09-05_Laurent_180.png', 2)\n",
      "tensor([0]) ('dataset_faces/blink/2018-10-03_Laurent_013.png', 0)\n",
      "tensor([3]) ('dataset_faces/right/2018-09-05_Laurent_077.png', 3)\n",
      "tensor([0]) ('dataset_faces/blink/2018-10-03_Laurent_040.png', 0)\n",
      "tensor([1]) ('dataset_faces/center/2018-09-04_Laurent_84.png', 1)\n",
      "tensor([1]) ('dataset_faces/center/2018-09-12_Laurent_226.png', 1)\n",
      "tensor([3]) ('dataset_faces/right/2018-09-12_Laurent_127.png', 3)\n",
      "tensor([2]) ('dataset_faces/left/2018-09-14_Laurent_217.png', 2)\n",
      "tensor([2]) ('dataset_faces/left/2018-09-12_Laurent_105.png', 2)\n",
      "tensor([3]) ('dataset_faces/right/2018-09-04_Laurent_3.png', 3)\n",
      "tensor([2]) ('dataset_faces/left/2018-09-14_Laurent_116.png', 2)\n",
      "tensor([0]) ('dataset_faces/blink/2018-10-03_Laurent_205.png', 0)\n",
      "tensor([3]) ('dataset_faces/right/2018-10-03_Laurent_115.png', 3)\n",
      "tensor([3]) ('dataset_faces/right/2018-09-14_Laurent_219.png', 3)\n",
      "tensor([1]) ('dataset_faces/center/2018-10-03_Laurent_240.png', 1)\n",
      "tensor([1]) ('dataset_faces/center/2018-09-05_Laurent_042.png', 1)\n",
      "tensor([0]) ('dataset_faces/blink/2018-09-12_Laurent_231.png', 0)\n",
      "tensor([3]) ('dataset_faces/right/2018-09-05_Laurent_060.png', 3)\n",
      "tensor([0]) ('dataset_faces/blink/2018-09-05_Laurent_098.png', 0)\n",
      "tensor([0]) ('dataset_faces/blink/2018-09-12_Laurent_016.png', 0)\n",
      "tensor([0]) ('dataset_faces/blink/2018-09-04_Laurent_176.png', 0)\n",
      "tensor([0]) ('dataset_faces/blink/2018-09-05_Laurent_225.png', 0)\n",
      "tensor([3]) ('dataset_faces/right/2018-09-05_Laurent_185.png', 3)\n",
      "tensor([1]) ('dataset_faces/center/2018-09-05_Laurent_071.png', 1)\n",
      "tensor([3]) ('dataset_faces/right/2018-09-05_Laurent_139.png', 3)\n",
      "tensor([3]) ('dataset_faces/right/2018-09-04_Laurent_98.png', 3)\n",
      "tensor([0]) ('dataset_faces/blink/2018-09-05_Laurent_186.png', 0)\n",
      "tensor([3]) ('dataset_faces/right/2018-09-05_Laurent_042.png', 3)\n",
      "tensor([1]) ('dataset_faces/center/2018-09-05_Laurent_003.png', 1)\n",
      "tensor([1]) ('dataset_faces/center/2018-10-03_Laurent_243.png', 1)\n",
      "tensor([3]) ('dataset_faces/right/2018-09-04_Laurent_80.png', 3)\n",
      "tensor([3]) ('dataset_faces/right/2018-10-03_Laurent_167.png', 3)\n",
      "tensor([1]) ('dataset_faces/center/2018-09-14_Laurent_240.png', 1)\n",
      "tensor([2]) ('dataset_faces/left/2018-09-05_Laurent_032.png', 2)\n",
      "tensor([1]) ('dataset_faces/center/2018-09-05_Laurent_203.png', 1)\n",
      "tensor([0]) ('dataset_faces/blink/2018-10-03_Laurent_224.png', 0)\n",
      "tensor([3]) ('dataset_faces/right/2018-10-03_Laurent_188.png', 3)\n",
      "tensor([1]) ('dataset_faces/center/2018-09-05_Laurent_144.png', 1)\n",
      "tensor([2]) ('dataset_faces/left/2018-09-04_Laurent_21.png', 2)\n",
      "tensor([0]) ('dataset_faces/blink/2018-10-03_Laurent_116.png', 0)\n",
      "tensor([2]) ('dataset_faces/left/2018-09-14_Laurent_225.png', 2)\n",
      "tensor([0]) ('dataset_faces/blink/2018-09-14_Laurent_170.png', 0)\n",
      "tensor([1]) ('dataset_faces/center/2018-09-05_Laurent_116.png', 1)\n",
      "tensor([3]) ('dataset_faces/right/2018-10-03_Laurent_053.png', 3)\n",
      "tensor([1]) ('dataset_faces/center/2018-09-04_Laurent_146.png', 1)\n",
      "tensor([0]) ('dataset_faces/blink/2018-09-05_Laurent_168.png', 0)\n",
      "tensor([2]) ('dataset_faces/left/2018-09-04_Laurent_129.png', 2)\n",
      "tensor([3]) ('dataset_faces/right/2018-09-05_Laurent_116.png', 3)\n",
      "tensor([3]) ('dataset_faces/right/2018-09-05_Laurent_010.png', 3)\n",
      "tensor([0]) ('dataset_faces/blink/2018-09-14_Laurent_044.png', 0)\n",
      "tensor([3]) ('dataset_faces/right/2018-09-12_Laurent_069.png', 3)\n",
      "tensor([3]) ('dataset_faces/right/2018-09-14_Laurent_117.png', 3)\n",
      "tensor([0]) ('dataset_faces/blink/2018-10-03_Laurent_247.png', 0)\n",
      "tensor([0]) ('dataset_faces/blink/2018-09-04_Laurent_63.png', 0)\n",
      "tensor([2]) ('dataset_faces/left/2018-10-03_Laurent_020.png', 2)\n",
      "tensor([3]) ('dataset_faces/right/2018-09-14_Laurent_055.png', 3)\n",
      "tensor([1]) ('dataset_faces/center/2018-09-14_Laurent_115.png', 1)\n",
      "tensor([2]) ('dataset_faces/left/2018-09-14_Laurent_019.png', 2)\n",
      "tensor([2]) ('dataset_faces/left/2018-09-04_Laurent_255.png', 2)\n",
      "tensor([2]) ('dataset_faces/left/2018-09-05_Laurent_091.png', 2)\n",
      "tensor([1]) ('dataset_faces/center/2018-09-05_Laurent_202.png', 1)\n",
      "tensor([1]) ('dataset_faces/center/2018-10-03_Laurent_198.png', 1)\n",
      "tensor([2]) ('dataset_faces/left/2018-09-05_Laurent_063.png', 2)\n",
      "tensor([1]) ('dataset_faces/center/2018-09-14_Laurent_143.png', 1)\n",
      "tensor([0]) ('dataset_faces/blink/2018-10-03_Laurent_078.png', 0)\n",
      "tensor([0]) ('dataset_faces/blink/2018-10-03_Laurent_024.png', 0)\n",
      "tensor([1]) ('dataset_faces/center/2018-09-05_Laurent_072.png', 1)\n",
      "tensor([0]) ('dataset_faces/blink/2018-09-05_Laurent_071.png', 0)\n",
      "tensor([2]) ('dataset_faces/left/2018-10-03_Laurent_118.png', 2)\n",
      "tensor([2]) ('dataset_faces/left/2018-09-14_Laurent_150.png', 2)\n",
      "tensor([0]) ('dataset_faces/blink/2018-09-12_Laurent_047.png', 0)\n",
      "tensor([2]) ('dataset_faces/left/2018-09-12_Laurent_236.png', 2)\n",
      "tensor([2]) ('dataset_faces/left/2018-09-12_Laurent_110.png', 2)\n",
      "tensor([1]) ('dataset_faces/center/2018-09-12_Laurent_068.png', 1)\n",
      "tensor([3]) ('dataset_faces/right/2018-09-05_Laurent_150.png', 3)\n",
      "tensor([2]) ('dataset_faces/left/2018-09-05_Laurent_078.png', 2)\n",
      "tensor([1]) ('dataset_faces/center/2018-10-03_Laurent_063.png', 1)\n",
      "tensor([2]) ('dataset_faces/left/2018-09-12_Laurent_077.png', 2)\n",
      "tensor([0]) ('dataset_faces/blink/2018-09-14_Laurent_035.png', 0)\n",
      "tensor([2]) ('dataset_faces/left/2018-10-03_Laurent_158.png', 2)\n",
      "tensor([1]) ('dataset_faces/center/2018-09-05_Laurent_211.png', 1)\n",
      "tensor([1]) ('dataset_faces/center/2018-09-04_Laurent_127.png', 1)\n",
      "tensor([2]) ('dataset_faces/left/2018-10-03_Laurent_008.png', 2)\n",
      "tensor([3]) ('dataset_faces/right/2018-10-03_Laurent_080.png', 3)\n",
      "tensor([1]) ('dataset_faces/center/2018-10-03_Laurent_119.png', 1)\n",
      "tensor([2]) ('dataset_faces/left/2018-09-12_Laurent_203.png', 2)\n",
      "tensor([1]) ('dataset_faces/center/2018-09-14_Laurent_249.png', 1)\n",
      "tensor([0]) ('dataset_faces/blink/2018-09-05_Laurent_140.png', 0)\n",
      "tensor([0]) ('dataset_faces/blink/2018-09-14_Laurent_181.png', 0)\n",
      "tensor([3]) ('dataset_faces/right/2018-09-14_Laurent_063.png', 3)\n",
      "tensor([1]) ('dataset_faces/center/2018-09-05_Laurent_089.png', 1)\n",
      "tensor([1]) ('dataset_faces/center/2018-09-05_Laurent_080.png', 1)\n",
      "tensor([0]) ('dataset_faces/blink/2018-09-12_Laurent_066.png', 0)\n",
      "tensor([1]) ('dataset_faces/center/2018-09-05_Laurent_055.png', 1)\n",
      "tensor([2]) ('dataset_faces/left/2018-09-04_Laurent_28.png', 2)\n",
      "tensor([2]) ('dataset_faces/left/2018-09-12_Laurent_131.png', 2)\n",
      "tensor([2]) ('dataset_faces/left/2018-09-04_Laurent_192.png', 2)\n",
      "tensor([2]) ('dataset_faces/left/2018-09-05_Laurent_052.png', 2)\n",
      "tensor([0]) ('dataset_faces/blink/2018-09-12_Laurent_125.png', 0)\n",
      "tensor([0]) ('dataset_faces/blink/2018-10-03_Laurent_059.png', 0)\n",
      "tensor([2]) ('dataset_faces/left/2018-09-12_Laurent_099.png', 2)\n",
      "tensor([0]) ('dataset_faces/blink/2018-09-05_Laurent_056.png', 0)\n",
      "tensor([0]) ('dataset_faces/blink/2018-09-05_Laurent_019.png', 0)\n",
      "tensor([0]) ('dataset_faces/blink/2018-09-05_Laurent_159.png', 0)\n",
      "tensor([2]) ('dataset_faces/left/2018-09-05_Laurent_124.png', 2)\n",
      "tensor([3]) ('dataset_faces/right/2018-09-05_Laurent_202.png', 3)\n",
      "tensor([2]) ('dataset_faces/left/2018-09-14_Laurent_227.png', 2)\n",
      "tensor([2]) ('dataset_faces/left/2018-09-05_Laurent_027.png', 2)\n",
      "tensor([2]) ('dataset_faces/left/2018-09-12_Laurent_146.png', 2)\n",
      "tensor([0]) ('dataset_faces/blink/2018-09-14_Laurent_133.png', 0)\n",
      "tensor([3]) ('dataset_faces/right/2018-10-03_Laurent_150.png', 3)\n",
      "tensor([2]) ('dataset_faces/left/2018-09-14_Laurent_172.png', 2)\n",
      "tensor([0]) ('dataset_faces/blink/2018-09-05_Laurent_085.png', 0)\n"
     ]
    }
   ],
   "source": [
    "for idx, (data, target) in enumerate(ml.dataset.test_loader):\n",
    "    print(target, ml.dataset.dataset.imgs[ml.dataset.test_loader.dataset.indices[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-05T16:54:06.449448Z",
     "start_time": "2018-10-05T16:54:06.385473Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ImageFolder' object has no attribute 'indices'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-5d6345d8c80b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'ImageFolder' object has no attribute 'indices'"
     ]
    }
   ],
   "source": [
    "for idx, (data, target) in enumerate(ml.dataset.dataset):\n",
    "    print(target, ml.dataset.dataset.imgs[ml.dataset.dataset.indices[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-05T16:54:17.649945Z",
     "start_time": "2018-10-05T16:54:07.303262Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for data, labels in ml.dataset.test_loader:\n",
    "    fig, ax = ml.show(only_wrong=False)\n",
    "    plt.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-04T13:30:46.862458Z",
     "start_time": "2018-10-04T13:29:53.624118Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for data, labels in ml.dataset.dataset:\n",
    "    fig, ax = ml.show(only_wrong=True)\n",
    "    plt.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-05T17:15:26.892098Z",
     "start_time": "2018-10-05T17:15:26.857758Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package torch.nn in torch:\n",
      "\n",
      "NAME\n",
      "    torch.nn\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    _functions (package)\n",
      "    backends (package)\n",
      "    functional\n",
      "    grad\n",
      "    init\n",
      "    modules (package)\n",
      "    parallel (package)\n",
      "    parameter\n",
      "    utils (package)\n",
      "\n",
      "FILE\n",
      "    /usr/local/lib/python3.6/site-packages/torch/nn/__init__.py\n",
      "\n",
      "\n",
      "Help on class Dropout2d in module torch.nn.modules.dropout:\n",
      "\n",
      "class Dropout2d(_DropoutNd)\n",
      " |  Randomly zeroes whole channels of the input tensor.\n",
      " |  The channels to zero-out are randomized on every forward call.\n",
      " |  \n",
      " |  Usually the input comes from :class:`nn.Conv2d` modules.\n",
      " |  \n",
      " |  As described in the paper\n",
      " |  `Efficient Object Localization Using Convolutional Networks`_ ,\n",
      " |  if adjacent pixels within feature maps are strongly correlated\n",
      " |  (as is normally the case in early convolution layers) then i.i.d. dropout\n",
      " |  will not regularize the activations and will otherwise just result\n",
      " |  in an effective learning rate decrease.\n",
      " |  \n",
      " |  In this case, :func:`nn.Dropout2d` will help promote independence between\n",
      " |  feature maps and should be used instead.\n",
      " |  \n",
      " |  Args:\n",
      " |      p (float, optional): probability of an element to be zero-ed.\n",
      " |      inplace (bool, optional): If set to ``True``, will do this operation\n",
      " |          in-place\n",
      " |  \n",
      " |  Shape:\n",
      " |      - Input: :math:`(N, C, H, W)`\n",
      " |      - Output: :math:`(N, C, H, W)` (same shape as input)\n",
      " |  \n",
      " |  Examples::\n",
      " |  \n",
      " |      >>> m = nn.Dropout2d(p=0.2)\n",
      " |      >>> input = torch.randn(20, 16, 32, 32)\n",
      " |      >>> output = m(input)\n",
      " |  \n",
      " |  .. _Efficient Object Localization Using Convolutional Networks:\n",
      " |     http://arxiv.org/abs/1411.4280\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Dropout2d\n",
      " |      _DropoutNd\n",
      " |      torch.nn.modules.module.Module\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  forward(self, input)\n",
      " |      Defines the computation performed at every call.\n",
      " |      \n",
      " |      Should be overridden by all subclasses.\n",
      " |      \n",
      " |      .. note::\n",
      " |          Although the recipe for forward pass needs to be defined within\n",
      " |          this function, one should call the :class:`Module` instance afterwards\n",
      " |          instead of this since the former takes care of running the\n",
      " |          registered hooks while the latter silently ignores them.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from _DropoutNd:\n",
      " |  \n",
      " |  __init__(self, p=0.5, inplace=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  extra_repr(self)\n",
      " |      Set the extra representation of the module\n",
      " |      \n",
      " |      To print customized extra information, you should reimplement\n",
      " |      this method in your own modules. Both single-line and multi-line\n",
      " |      strings are acceptable.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __call__(self, *input, **kwargs)\n",
      " |      Call self as a function.\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __dir__(self)\n",
      " |      __dir__() -> list\n",
      " |      default dir() implementation\n",
      " |  \n",
      " |  __getattr__(self, name)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  add_module(self, name, module)\n",
      " |      Adds a child module to the current module.\n",
      " |      \n",
      " |      The module can be accessed as an attribute using the given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the child module. The child module can be\n",
      " |              accessed from this module using the given name\n",
      " |          parameter (Module): child module to be added to the module.\n",
      " |  \n",
      " |  apply(self, fn)\n",
      " |      Applies ``fn`` recursively to every submodule (as returned by ``.children()``)\n",
      " |      as well as self. Typical use includes initializing the parameters of a model\n",
      " |      (see also :ref:`torch-nn-init`).\n",
      " |      \n",
      " |      Args:\n",
      " |          fn (:class:`Module` -> None): function to be applied to each submodule\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> def init_weights(m):\n",
      " |                  print(m)\n",
      " |                  if type(m) == nn.Linear:\n",
      " |                      m.weight.data.fill_(1.0)\n",
      " |                      print(m.weight)\n",
      " |      \n",
      " |          >>> net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\n",
      " |          >>> net.apply(init_weights)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 1.,  1.],\n",
      " |                  [ 1.,  1.]])\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 1.,  1.],\n",
      " |                  [ 1.,  1.]])\n",
      " |          Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |          Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |  \n",
      " |  children(self)\n",
      " |      Returns an iterator over immediate children modules.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a child module\n",
      " |  \n",
      " |  cpu(self)\n",
      " |      Moves all model parameters and buffers to the CPU.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  cuda(self, device=None)\n",
      " |      Moves all model parameters and buffers to the GPU.\n",
      " |      \n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing optimizer if the module will\n",
      " |      live on GPU while being optimized.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  double(self)\n",
      " |      Casts all floating point parameters and buffers to ``double`` datatype.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  eval(self)\n",
      " |      Sets the module in evaluation mode.\n",
      " |      \n",
      " |      This has any effect only on certain modules. See documentations of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |  \n",
      " |  float(self)\n",
      " |      Casts all floating point parameters and buffers to float datatype.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  half(self)\n",
      " |      Casts all floating point parameters and buffers to ``half`` datatype.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  load_state_dict(self, state_dict, strict=True)\n",
      " |      Copies parameters and buffers from :attr:`state_dict` into\n",
      " |      this module and its descendants. If :attr:`strict` is ``True``, then\n",
      " |      the keys of :attr:`state_dict` must exactly match the keys returned\n",
      " |      by this module's :meth:`~torch.nn.Module.state_dict` function.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          state_dict (dict): a dict containing parameters and\n",
      " |              persistent buffers.\n",
      " |          strict (bool, optional): whether to strictly enforce that the keys\n",
      " |              in :attr:`state_dict` match the keys returned by this module's\n",
      " |              :meth:`~torch.nn.Module.state_dict` function. Default: ``True``\n",
      " |  \n",
      " |  modules(self)\n",
      " |      Returns an iterator over all modules in the network.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a module in the network\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.modules()):\n",
      " |                  print(idx, '->', m)\n",
      " |      \n",
      " |          0 -> Sequential (\n",
      " |            (0): Linear (2 -> 2)\n",
      " |            (1): Linear (2 -> 2)\n",
      " |          )\n",
      " |          1 -> Linear (2 -> 2)\n",
      " |  \n",
      " |  named_children(self)\n",
      " |      Returns an iterator over immediate children modules, yielding both\n",
      " |      the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Module): Tuple containing a name and child module\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for name, module in model.named_children():\n",
      " |          >>>     if name in ['conv4', 'conv5']:\n",
      " |          >>>         print(module)\n",
      " |  \n",
      " |  named_modules(self, memo=None, prefix='')\n",
      " |      Returns an iterator over all modules in the network, yielding\n",
      " |      both the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Module): Tuple of name and module\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.named_modules()):\n",
      " |                  print(idx, '->', m)\n",
      " |      \n",
      " |          0 -> ('', Sequential (\n",
      " |            (0): Linear (2 -> 2)\n",
      " |            (1): Linear (2 -> 2)\n",
      " |          ))\n",
      " |          1 -> ('0', Linear (2 -> 2))\n",
      " |  \n",
      " |  named_parameters(self, memo=None, prefix='')\n",
      " |      Returns an iterator over module parameters, yielding both the\n",
      " |      name of the parameter as well as the parameter itself\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Parameter): Tuple containing the name and parameter\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for name, param in self.named_parameters():\n",
      " |          >>>    if name in ['bias']:\n",
      " |          >>>        print(param.size())\n",
      " |  \n",
      " |  parameters(self)\n",
      " |      Returns an iterator over module parameters.\n",
      " |      \n",
      " |      This is typically passed to an optimizer.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Parameter: module parameter\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for param in model.parameters():\n",
      " |          >>>     print(type(param.data), param.size())\n",
      " |          <class 'torch.FloatTensor'> (20L,)\n",
      " |          <class 'torch.FloatTensor'> (20L, 1L, 5L, 5L)\n",
      " |  \n",
      " |  register_backward_hook(self, hook)\n",
      " |      Registers a backward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time the gradients with respect to module\n",
      " |      inputs are computed. The hook should have the following signature::\n",
      " |      \n",
      " |          hook(module, grad_input, grad_output) -> Tensor or None\n",
      " |      \n",
      " |      The :attr:`grad_input` and :attr:`grad_output` may be tuples if the\n",
      " |      module has multiple inputs or outputs. The hook should not modify its\n",
      " |      arguments, but it can optionally return a new gradient with respect to\n",
      " |      input that will be used in place of :attr:`grad_input` in subsequent\n",
      " |      computations.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_buffer(self, name, tensor)\n",
      " |      Adds a persistent buffer to the module.\n",
      " |      \n",
      " |      This is typically used to register a buffer that should not to be\n",
      " |      considered a model parameter. For example, BatchNorm's ``running_mean``\n",
      " |      is not a parameter, but is part of the persistent state.\n",
      " |      \n",
      " |      Buffers can be accessed as attributes using given names.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the buffer. The buffer can be accessed\n",
      " |              from this module using the given name\n",
      " |          tensor (Tensor): buffer to be registered.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> self.register_buffer('running_mean', torch.zeros(num_features))\n",
      " |  \n",
      " |  register_forward_hook(self, hook)\n",
      " |      Registers a forward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time after :func:`forward` has computed an output.\n",
      " |      It should have the following signature::\n",
      " |      \n",
      " |          hook(module, input, output) -> None\n",
      " |      \n",
      " |      The hook should not modify the input or output.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_forward_pre_hook(self, hook)\n",
      " |      Registers a forward pre-hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time before :func:`forward` is invoked.\n",
      " |      It should have the following signature::\n",
      " |      \n",
      " |          hook(module, input) -> None\n",
      " |      \n",
      " |      The hook should not modify the input.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_parameter(self, name, param)\n",
      " |      Adds a parameter to the module.\n",
      " |      \n",
      " |      The parameter can be accessed as an attribute using given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the parameter. The parameter can be accessed\n",
      " |              from this module using the given name\n",
      " |          parameter (Parameter): parameter to be added to the module.\n",
      " |  \n",
      " |  share_memory(self)\n",
      " |  \n",
      " |  state_dict(self, destination=None, prefix='', keep_vars=False)\n",
      " |      Returns a dictionary containing a whole state of the module.\n",
      " |      \n",
      " |      Both parameters and persistent buffers (e.g. running averages) are\n",
      " |      included. Keys are corresponding parameter and buffer names.\n",
      " |      \n",
      " |      Returns:\n",
      " |          dict:\n",
      " |              a dictionary containing a whole state of the module\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> module.state_dict().keys()\n",
      " |          ['bias', 'weight']\n",
      " |  \n",
      " |  to(self, *args, **kwargs)\n",
      " |      Moves and/or casts the parameters and buffers.\n",
      " |      \n",
      " |      This can be called as\n",
      " |      \n",
      " |      .. function:: to(device=None, dtype=None, non_blocking=False)\n",
      " |      \n",
      " |      .. function:: to(dtype, non_blocking=False)\n",
      " |      \n",
      " |      .. function:: to(tensor, non_blocking=False)\n",
      " |      \n",
      " |      Its signature is similar to :meth:`torch.Tensor.to`, but only accepts\n",
      " |      floating point desired :attr:`dtype` s. In addition, this method will\n",
      " |      only cast the floating point parameters and buffers to :attr:`dtype`\n",
      " |      (if given). The integral parameters and buffers will be moved\n",
      " |      :attr:`device`, if that is given, but with dtypes unchanged. When\n",
      " |      :attr:`non_blocking` is set, it tries to convert/move asynchronously\n",
      " |      with respect to the host if possible, e.g., moving CPU Tensors with\n",
      " |      pinned memory to CUDA devices.\n",
      " |      \n",
      " |      See below for examples.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (:class:`torch.device`): the desired device of the parameters\n",
      " |              and buffers in this module\n",
      " |          dtype (:class:`torch.dtype`): the desired floating point type of\n",
      " |              the floating point parameters and buffers in this module\n",
      " |          tensor (torch.Tensor): Tensor whose dtype and device are the desired\n",
      " |              dtype and device for all parameters and buffers in this module\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> linear = nn.Linear(2, 2)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]])\n",
      " |          >>> linear.to(torch.double)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]], dtype=torch.float64)\n",
      " |          >>> gpu1 = torch.device(\"cuda:1\")\n",
      " |          >>> linear.to(gpu1, dtype=torch.half, non_blocking=True)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n",
      " |          >>> cpu = torch.device(\"cpu\")\n",
      " |          >>> linear.to(cpu)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16)\n",
      " |  \n",
      " |  train(self, mode=True)\n",
      " |      Sets the module in training mode.\n",
      " |      \n",
      " |      This has any effect only on certain modules. See documentations of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  type(self, dst_type)\n",
      " |      Casts all parameters and buffers to :attr:`dst_type`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          dst_type (type or string): the desired type\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  zero_grad(self)\n",
      " |      Sets gradients of all model parameters to zero.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  dump_patches = False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "help(nn)\n",
    "help(nn.Dropout2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nteract": {
   "version": "0.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
