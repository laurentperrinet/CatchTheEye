{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T13:30:52.907010Z",
     "start_time": "2018-10-19T13:30:52.871207Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T13:30:53.582663Z",
     "start_time": "2018-10-19T13:30:52.911896Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-19T13:30:54.518017Z",
     "start_time": "2018-10-19T13:30:53.588219Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "Software versions": [
        {
         "module": "Python",
         "version": "3.6.5 64bit [GCC 4.2.1 Compatible Apple LLVM 9.1.0 (clang-902.0.39.2)]"
        },
        {
         "module": "IPython",
         "version": "7.0.1"
        },
        {
         "module": "OS",
         "version": "Darwin 18.0.0 x86_64 i386 64bit"
        },
        {
         "module": "numpy",
         "version": "1.15.2"
        },
        {
         "module": "dlib",
         "version": "19.16.0"
        },
        {
         "module": "matplotlib",
         "version": "3.0.0"
        },
        {
         "module": "imageio",
         "version": "2.4.1"
        },
        {
         "module": "gaze",
         "version": "The 'gaze' distribution was not found and is required by the application"
        },
        {
         "module": "torch",
         "version": "0.4.1"
        },
        {
         "module": "torchvision",
         "version": "0.2.1"
        }
       ]
      },
      "text/html": [
       "<table><tr><th>Software</th><th>Version</th></tr><tr><td>Python</td><td>3.6.5 64bit [GCC 4.2.1 Compatible Apple LLVM 9.1.0 (clang-902.0.39.2)]</td></tr><tr><td>IPython</td><td>7.0.1</td></tr><tr><td>OS</td><td>Darwin 18.0.0 x86_64 i386 64bit</td></tr><tr><td>numpy</td><td>1.15.2</td></tr><tr><td>dlib</td><td>19.16.0</td></tr><tr><td>matplotlib</td><td>3.0.0</td></tr><tr><td>imageio</td><td>2.4.1</td></tr><tr><td>gaze</td><td>The 'gaze' distribution was not found and is required by the application</td></tr><tr><td>torch</td><td>0.4.1</td></tr><tr><td>torchvision</td><td>0.2.1</td></tr><tr><td colspan='2'>Fri Oct 19 15:30:54 2018 CEST</td></tr></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{|l|l|}\\hline\n",
       "{\\bf Software} & {\\bf Version} \\\\ \\hline\\hline\n",
       "Python & 3.6.5 64bit [GCC 4.2.1 Compatible Apple LLVM 9.1.0 (clang-902.0.39.2)] \\\\ \\hline\n",
       "IPython & 7.0.1 \\\\ \\hline\n",
       "OS & Darwin 18.0.0 x86\\_64 i386 64bit \\\\ \\hline\n",
       "numpy & 1.15.2 \\\\ \\hline\n",
       "dlib & 19.16.0 \\\\ \\hline\n",
       "matplotlib & 3.0.0 \\\\ \\hline\n",
       "imageio & 2.4.1 \\\\ \\hline\n",
       "gaze & The 'gaze' distribution was not found and is required by the application \\\\ \\hline\n",
       "torch & 0.4.1 \\\\ \\hline\n",
       "torchvision & 0.2.1 \\\\ \\hline\n",
       "\\hline \\multicolumn{2}{|l|}{Fri Oct 19 15:30:54 2018 CEST} \\\\ \\hline\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "Software versions\n",
       "Python 3.6.5 64bit [GCC 4.2.1 Compatible Apple LLVM 9.1.0 (clang-902.0.39.2)]\n",
       "IPython 7.0.1\n",
       "OS Darwin 18.0.0 x86_64 i386 64bit\n",
       "numpy 1.15.2\n",
       "dlib 19.16.0\n",
       "matplotlib 3.0.0\n",
       "imageio 2.4.1\n",
       "gaze The 'gaze' distribution was not found and is required by the application\n",
       "torch 0.4.1\n",
       "torchvision 0.2.1\n",
       "Fri Oct 19 15:30:54 2018 CEST"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext version_information\n",
    "%version_information numpy, dlib, matplotlib, imageio, gaze, torch, torchvision"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import time\n",
    "time.sleep(8*3600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training the model on the cropped faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-10-19T13:30:52.852Z"
    }
   },
   "outputs": [],
   "source": [
    "from gaze import init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-10-19T13:30:52.857Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 400\n",
    "args = init(verbose=1, epochs=epochs)\n",
    "\n",
    "path = '_Regard_400.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-10-19T13:30:52.861Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 4000\n",
    "args = init(verbose=1, epochs=epochs)\n",
    "\n",
    "path = '_Regard_4000.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-10-19T13:30:52.865Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "args = init(verbose=1)\n",
    "path = '_Regard.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-10-19T13:30:52.869Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters= {'dataset_folder': 'dataset', 'dataset_faces_folder': 'dataset_faces', 'batch_size': 16, 'test_batch_size': 8, 'size_test_set': 0.2, 'epochs': 40, 'do_adam': False, 'lr': 0.01, 'momentum': 0.05, 'no_cuda': False, 'num_processes': 1, 'seed': 42, 'log_interval': 0, 'fullsize': 75, 'crop': 64, 'size': 90, 'mean': 0.4, 'std': 0.3, 'conv1_dim': 9, 'conv1_kernel_size': 18, 'conv2_dim': 36, 'conv2_kernel_size': 14, 'conv1_bn_momentum': 0.5, 'conv2_bn_momentum': 0.5, 'dense_bn_momentum': 0.9, 'stride1': 2, 'stride2': 4, 'N_cv': 20, 'dimension': 30, 'verbose': 1}\n",
      "ls: _Regard.pt: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "print('Parameters=', args)\n",
    "!ls -l {path}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!rm {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-10-19T13:30:52.891Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Train Epoch:   0%|          | 0/40 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2221 sample images;  1777  to train 444 to test\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Train Epoch:   2%|â–Ž         | 1/40 [01:03<41:06, 63.24s/it]"
     ]
    }
   ],
   "source": [
    "from gaze import ML\n",
    "ml = ML(args)\n",
    "ml.train(path=path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-10-19T13:30:52.897Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Accuracy = ml.test()\n",
    "print('Accuracy={:.1f}%'.format(Accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing the one which are wrong:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "max(ml.dataset.test_loader.dataset.indices)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ml.dataset.dataset.imgs[0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ml.dataset.dataset.imgs[0][0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for idx, (data, target) in enumerate(ml.dataset.test_loader):\n",
    "    print(target, ml.dataset.dataset.imgs[ml.dataset.test_loader.dataset.indices[idx]])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "for idx, (data, target) in enumerate(ml.dataset.dataset):\n",
    "    print(target, ml.dataset.dataset.imgs[ml.dataset.dataset.indices[idx]])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "for data, labels in ml.dataset.test_loader:\n",
    "    fig, ax = ml.show(only_wrong=False)\n",
    "    plt.show() \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "for data, labels in ml.dataset.dataset:\n",
    "    fig, ax = ml.show(only_wrong=True)\n",
    "    plt.show() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## showing the images which are wrongly classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-10-19T13:30:53.027Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import glob\n",
    "import imageio\n",
    "from gaze import FaceExtractor\n",
    "FE = FaceExtractor()\n",
    "timings = []\n",
    "wrongs = []\n",
    "for target in ml.dataset.classes:\n",
    "    for filename in glob.glob(os.path.join(args.dataset_folder, target, '*.png')):\n",
    "        if False:\n",
    "            frame = imageio.imread(filename)\n",
    "            img_face = FE.face_extractor(frame)\n",
    "        else:\n",
    "            filename_face = filename.replace(args.dataset_folder, args.dataset_faces_folder)\n",
    "            img_face = imageio.imread(filename_face)\n",
    "\n",
    "        pred = ml.classify(img_face, ml.dataset.test_transform)\n",
    "        pred_label = ml.dataset.dataset.classes[pred.argmax()]\n",
    "        if not pred_label == target:\n",
    "            wrong = dict(filename=filename, pred_label=pred_label, target=target)\n",
    "            wrongs.append(wrong)\n",
    "            print('For ', filename, ', Pred =', pred_label, 'True =', target, ', P=', ['%.3f' % p for p in pred])\n",
    "            #plt.imshow(img_face)\n",
    "            #plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## skim through images which were wrongly classified\n",
    "\n",
    "Some images were obviously misclassified at the supervision level, let's try to fix that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-10-19T13:30:53.032Z"
    }
   },
   "outputs": [],
   "source": [
    "def view_image(wrong):\n",
    "    filename = wrong['filename']\n",
    "    filename_face = filename.replace(args.dataset_folder, args.dataset_faces_folder)\n",
    "    img_face = imageio.imread(filename_face)\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(15, 8))\n",
    "    ax.imshow(img_face)\n",
    "    ax.set_title('Pred: %s / True: %s ' % (wrong['pred_label'], wrong['target']))\n",
    "    #plt.show()\n",
    "\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from ipywidgets import interactive\n",
    "def f(i, action):\n",
    "    wrong = wrongs[i]\n",
    "    view_image(wrong)\n",
    "    filename = wrong['filename']\n",
    "    filename_face = filename.replace(args.dataset_folder, args.dataset_faces_folder)\n",
    "\n",
    "    if action == 'Remove':\n",
    "        print('removing...', filename)\n",
    "        os.remove(filename_face)\n",
    "        os.remove(filename)\n",
    "    elif action == 'Change':\n",
    "        print('Changing...', filename, ' to ', filename.replace(wrongs[i]['target'], wrongs[i]['pred_label']))\n",
    "        import shutil\n",
    "        shutil.move(filename, filename.replace(wrongs[i]['target'], wrongs[i]['pred_label']))\n",
    "        shutil.move(filename_face, filename_face.replace(wrongs[i]['target'], wrongs[i]['pred_label']))\n",
    "        wrongs[i]['filename'] = filename.replace(wrongs[i]['target'], wrongs[i]['pred_label'])\n",
    "        wrongs[i]['target'] = wrongs[i]['pred_label']\n",
    "        \n",
    "    #display(b)\n",
    "    return action\n",
    "\n",
    "w = interactive(f, i=widgets.IntSlider(min=0, max=len(wrongs)-1, step=1, value=0, readout=True), action=widgets.ToggleButtons(options=['Keep', 'Remove', 'Change']))\n",
    "display(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## showing the trained weights\n",
    "\n",
    "https://github.com/utkuozbulak/pytorch-cnn-visualizations/blob/master/README.md\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-10-19T13:30:53.038Z"
    }
   },
   "outputs": [],
   "source": [
    "child = ml.model.children()\n",
    "\n",
    "convolayer = [i for i in ml.model.children()][1]\n",
    "convolayer\n",
    "\n",
    "weights = convolayer.weight.data.clone()\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-10-19T13:30:53.042Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from torchvision import utils\n",
    "\n",
    "def plotkernel(tensor, figname, ch=0, allkernels=False, nrow=3, padding=1):\n",
    "    n, c, w, h = tensor.shape\n",
    "    if allkernels: tensor = tensor.view(n*c,-1,w,h )\n",
    "    elif c != 3: tensor = tensor[:,ch,:,:].unsqueeze(dim=1)\n",
    "        \n",
    "    rows = np.min( (tensor.shape[0]//nrow + 1, 64 )  )    \n",
    "    grid = utils.make_grid(tensor, nrow=nrow, normalize=True, padding=padding)\n",
    "    fig, ax = plt.subplots( figsize=(nrow,rows))\n",
    "    ax.imshow(grid.numpy().transpose((1, 2, 0)))\n",
    "    plt.setp(ax, xticks=[], yticks=[])\n",
    "\n",
    "    plt.savefig(figname)\n",
    "\n",
    "for i, weights in enumerate([ml.model.conv1.weight.data.clone(), ml.model.conv2.weight.data.clone()]):\n",
    "    plotkernel(weights, figname = 'figures/kernel_layer' + str(i) + '.png')\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nteract": {
   "version": "0.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
